{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo RSM Simulator\n",
    "\n",
    "This notebook demonstrates how to use the Monte Carlo simulator to analyze RSM (Replicated State Machine) deployments. We'll explore:\n",
    "\n",
    "1. Setting up node configurations with failure distributions\n",
    "2. Running single simulations\n",
    "3. Running Monte Carlo simulations for statistical analysis\n",
    "4. Visualizing availability and time-to-data-loss distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from powder.simulation import (\n",
    "    # Time units\n",
    "    Seconds, hours, days, minutes,\n",
    "    # Distributions\n",
    "    Exponential, Weibull, Normal, Uniform, Constant,\n",
    "    # Node\n",
    "    NodeConfig, NodeState,\n",
    "    # Network\n",
    "    NetworkConfig, NetworkState,\n",
    "    # Cluster\n",
    "    ClusterState,\n",
    "    # Strategy\n",
    "    NoOpStrategy, SimpleReplacementStrategy, NodeReplacementStrategy,\n",
    "    # Protocol\n",
    "    LeaderlessUpToDateQuorumProtocol, LeaderlessMajorityAvailableProtocol, RaftLikeProtocol,\n",
    "    # Simulator\n",
    "    Simulator,\n",
    ")\n",
    "from powder.monte_carlo import (\n",
    "    run_monte_carlo, MonteCarloConfig, MonteCarloRunner,\n",
    "    run_monte_carlo_converged, ConvergenceCriteria, ConvergenceMetric,\n",
    "    estimate_required_runs,\n",
    ")\n",
    "from powder.graphing_utils import (\n",
    "    make_pdf_histogram,\n",
    "    make_cdf_plot,\n",
    "    make_availability_boxplot,\n",
    "    make_time_to_loss_comparison,\n",
    "    make_multi_cdf_plot,\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Node Configuration\n",
    "\n",
    "Each node has:\n",
    "- **region**: Geographic location\n",
    "- **cost_per_hour**: Dollar cost to run the node\n",
    "- **failure_dist**: Distribution for time until transient failure\n",
    "- **recovery_dist**: Distribution for time to recover from failure\n",
    "- **data_loss_dist**: Distribution for time until permanent data loss (e.g., disk failure)\n",
    "- **log_replay_rate_dist**: Distribution for log replay rate (committed-data units replayed per second of wall time)\n",
    "- **snapshot_download_time_dist**: Distribution for wall-clock time to download a full snapshot\n",
    "- **spawn_dist**: Distribution for time to spawn a new replacement node\n",
    "\n",
    "Snapshot interval and commit rate are configured on the Protocol, not on individual nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic node configuration\n",
    "def make_standard_node_config(region: str = \"us-east\") -> NodeConfig:\n",
    "    return NodeConfig(\n",
    "        region=region,\n",
    "        cost_per_hour=0.50,  # $0.50/hour per node\n",
    "        # Transient failures: ~1 per week on average\n",
    "        failure_dist=Exponential(rate=1 / days(7)),\n",
    "        # Recovery time: 5-15 minutes\n",
    "        recovery_dist=Uniform(low=minutes(5), high=minutes(15)),\n",
    "        # Permanent data loss: ~1 per year (disk failure rate)\n",
    "        data_loss_dist=Exponential(rate=1 / days(365)),\n",
    "        # Log replay rate: node can replay 3 units of committed data per 1 second of wall time\n",
    "        log_replay_rate_dist=Constant(3.0),\n",
    "        # Snapshot download time: 5 minutes to download a full snapshot\n",
    "        snapshot_download_time_dist=Constant(minutes(5)),\n",
    "        # Spawn time: 10-20 minutes to provision a new node\n",
    "        spawn_dist=Uniform(low=minutes(1), high=minutes(5)),\n",
    "    )\n",
    "\n",
    "node_config = make_standard_node_config()\n",
    "print(f\"Node config: {node_config.region}, ${node_config.cost_per_hour}/hr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Initial Cluster\n",
    "\n",
    "A cluster consists of multiple nodes. For a 3-node cluster, we need a quorum of 2 nodes to commit new requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster(num_nodes: int = 3, regions: list[str] | None = None) -> ClusterState:\n",
    "    \"\"\"Create a fresh cluster with the specified number of nodes.\"\"\"\n",
    "    if regions is None:\n",
    "        regions = [\"us-east\", \"us-west\", \"eu-central\"]\n",
    "    \n",
    "    nodes = {}\n",
    "    for i in range(num_nodes):\n",
    "        region = regions[i % len(regions)]\n",
    "        config = make_standard_node_config(region)\n",
    "        nodes[f\"node{i}\"] = NodeState(\n",
    "            node_id=f\"node{i}\",\n",
    "            config=config,\n",
    "        )\n",
    "    \n",
    "    return ClusterState(\n",
    "        nodes=nodes,\n",
    "        network=NetworkState(),\n",
    "        target_cluster_size=num_nodes,\n",
    "    )\n",
    "\n",
    "cluster = create_cluster(3)\n",
    "print(f\"Created cluster: {cluster}\")\n",
    "print(f\"Quorum size: {cluster.quorum_size()}\")\n",
    "print(f\"Can commit: {cluster.can_commit()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run a Single Simulation\n",
    "\n",
    "Let's run a simulation for 30 days and observe the behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation for 30 days with no intervention strategy\n",
    "cluster = create_cluster(3)\n",
    "simulator = Simulator(\n",
    "    initial_cluster=cluster,\n",
    "    strategy=NoOpStrategy(),\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    seed=42,\n",
    "    log_events=True,  # Keep event log for debugging\n",
    ")\n",
    "\n",
    "result = simulator.run_for(days(1000))\n",
    "\n",
    "print(f\"Simulation ended: {result.end_reason}\")\n",
    "print(f\"End time: {result.end_time / 86400:.2f} days\")\n",
    "print(f\"Availability: {result.metrics.availability_fraction() * 100:.2f}%\")\n",
    "print(f\"Total cost: ${result.metrics.total_cost:.2f}\")\n",
    "print(f\"Events processed: {len(result.event_log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all node_sync_complete events\n",
    "from powder.simulation.events import EventType\n",
    "sync_events = [e for e in result.event_log if e.event_type == EventType.NODE_SYNC_COMPLETE]\n",
    "print(f\"Node sync complete events: {len(sync_events)}\")\n",
    "for event in sync_events:\n",
    "    print(f\"  t={event.time/3600:.2f}h ({event.time/86400:.1f}d): {event.event_type.value} on {event.target_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Monte Carlo Simulations\n",
    "\n",
    "To get statistical properties, we run many simulations and aggregate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 100 simulations, each for 1 year, with NoOp strategy\n",
    "results_no_op = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=NoOpStrategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(results_no_op.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run with SimpleReplacementStrategy that spawns replacements for failed nodes\n",
    "def make_replacement_strategy():\n",
    "    return SimpleReplacementStrategy(\n",
    "        default_node_config=make_standard_node_config(),\n",
    "        scale_down_threshold=3,  # Only scale down if 3+ nodes fail simultaneously\n",
    "    )\n",
    "\n",
    "results_with_replacement = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(results_with_replacement.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Node Replacement Strategy — Timeout-Based Replacement\n",
    "\n",
    "The `NodeReplacementStrategy` models the standard production protocol for handling\n",
    "node failures in replicated state machines. Unlike `SimpleReplacementStrategy`\n",
    "which only replaces nodes after permanent data loss, this strategy also replaces\n",
    "nodes that have been **unavailable for too long** due to transient failures or\n",
    "network outages.\n",
    "\n",
    "**How it works:**\n",
    "1. When a node becomes unavailable, a configurable **failure timeout** countdown begins.\n",
    "2. If the node recovers before the timeout, the countdown is cancelled.\n",
    "3. If the timeout fires and the node is still unavailable *and* the cluster can still\n",
    "   commit, the failed node is removed and a replacement is spawned.\n",
    "4. For permanent data loss, replacement is immediate — no timeout wait.\n",
    "\n",
    "The `failure_timeout` should be set longer than the typical recovery time to avoid\n",
    "unnecessary replacements for transient failures that resolve quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NodeReplacementStrategy: replace nodes that are unavailable too long\n",
    "# The timeout is set to 30 minutes — longer than the typical 5-15 min recovery,\n",
    "# so transient failures that resolve quickly won't trigger unnecessary replacements.\n",
    "\n",
    "def make_node_replacement_strategy():\n",
    "    return NodeReplacementStrategy(\n",
    "        failure_timeout=minutes(30),\n",
    "        default_node_config=make_standard_node_config(),\n",
    "    )\n",
    "\n",
    "results_node_replacement = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_node_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"NodeReplacementStrategy (timeout-based):\")\n",
    "print(results_node_replacement.summary())\n",
    "\n",
    "print(\"\\nFor comparison, SimpleReplacementStrategy (data-loss only):\")\n",
    "print(results_with_replacement.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three strategies\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=[results_no_op, results_with_replacement, results_node_replacement],\n",
    "    labels=[\"No Intervention\", \"Simple Replacement\", \"Node Replacement (30min timeout)\"],\n",
    "    title=\"Availability: No-Op vs Simple Replacement vs Node Replacement\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-run event log to see the replacement strategy in action\n",
    "cluster = create_cluster(3)\n",
    "simulator = Simulator(\n",
    "    initial_cluster=cluster,\n",
    "    strategy=NodeReplacementStrategy(\n",
    "        failure_timeout=minutes(30),\n",
    "        default_node_config=make_standard_node_config(),\n",
    "    ),\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    seed=42,\n",
    "    log_events=True,\n",
    ")\n",
    "\n",
    "result = simulator.run_for(days(365))\n",
    "print(f\"End reason: {result.end_reason}\")\n",
    "print(f\"Availability: {result.metrics.availability_fraction() * 100:.2f}%\")\n",
    "print(f\"Events: {len(result.event_log)}\")\n",
    "\n",
    "# Show replacement-related events\n",
    "print(\"\\nReplacement-related events:\")\n",
    "from powder.simulation.events import EventType\n",
    "for event in result.event_log:\n",
    "    if event.event_type in (\n",
    "        EventType.NODE_DATA_LOSS,\n",
    "        EventType.NODE_REPLACEMENT_TIMEOUT,\n",
    "        EventType.NODE_SPAWN_COMPLETE,\n",
    "    ):\n",
    "        print(f\"  t={event.time/86400:.2f}d: {event.event_type.value} on {event.target_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. Adaptive Monte Carlo — Automatic Sample Size\n",
    "\n",
    "Instead of guessing how many simulations to run, we can let the runner\n",
    "automatically determine the required number of runs to achieve a desired\n",
    "confidence level and relative error on key metrics.\n",
    "\n",
    "The runner works in two phases:\n",
    "1. **Pilot batch**: Runs `min_runs` simulations to estimate variance.\n",
    "2. **Adaptive batches**: Uses the t-distribution CI formula `n = (t * σ / (ε * μ))²`\n",
    "   to estimate how many more runs are needed, running them in batches until all\n",
    "   target metrics converge or `max_runs` is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run adaptive Monte Carlo — converge on availability with 95% CI, 5% relative error\n",
    "converged_result = run_monte_carlo_converged(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    max_time=days(365),\n",
    "    confidence_level=0.95,\n",
    "    relative_error=0.05,  # CI half-width <= 5% of the mean\n",
    "    metrics=[ConvergenceMetric.AVAILABILITY],\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    "    min_runs=30,\n",
    "    max_runs=5000,\n",
    "    batch_size=20,\n",
    ")\n",
    "\n",
    "print(converged_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converge on multiple metrics simultaneously\n",
    "# The runner will keep going until ALL specified metrics are within tolerance.\n",
    "converged_multi = run_monte_carlo_converged(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    max_time=days(365),\n",
    "    confidence_level=0.95,\n",
    "    relative_error=0.05,\n",
    "    metrics=[\n",
    "        ConvergenceMetric.AVAILABILITY,\n",
    "        ConvergenceMetric.COST,\n",
    "        ConvergenceMetric.DATA_LOSS_PROBABILITY,\n",
    "    ],\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    "    min_runs=30,\n",
    "    max_runs=5000,\n",
    "    batch_size=20,\n",
    ")\n",
    "\n",
    "print(converged_multi.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also estimate required runs from a small pilot before committing\n",
    "# to a full adaptive run. This is useful for planning compute budgets.\n",
    "pilot = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=30,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "estimates = estimate_required_runs(\n",
    "    pilot,\n",
    "    ConvergenceCriteria(\n",
    "        confidence_level=0.95,\n",
    "        relative_error=0.02,\n",
    "        metrics=[ConvergenceMetric.AVAILABILITY, ConvergenceMetric.COST],\n",
    "    ),\n",
    ")\n",
    "\n",
    "for metric, n in estimates.items():\n",
    "    print(f\"  {metric.value}: ~{n} runs needed for 95% CI with 5% relative error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Watch convergence happen in real-time\n",
    "#\n",
    "# This uses a progress callback to print status after every batch,\n",
    "# so you can see the estimated sample size shrink as variance stabilises.\n",
    "\n",
    "print(f\"{'Completed':>10} {'Est. Total':>11} {'Converged':>10}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "def on_progress(completed, estimated_total, converged):\n",
    "    print(f\"{completed:>10} {estimated_total:>11} {'  yes' if converged else '   no':>10}\")\n",
    "\n",
    "converged_example = run_monte_carlo_converged(\n",
    "    cluster_factory=lambda: create_cluster(5),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    max_time=days(365),\n",
    "    confidence_level=0.95,\n",
    "    relative_error=0.05,\n",
    "    metrics=[ConvergenceMetric.AVAILABILITY, ConvergenceMetric.COST],\n",
    "    stop_on_data_loss=True,\n",
    "    seed=123,\n",
    "    min_runs=30,\n",
    "    max_runs=2000,\n",
    "    batch_size=20,\n",
    "    progress_callback=on_progress,\n",
    ")\n",
    "\n",
    "print()\n",
    "print(f\"Finished in {converged_example.total_runs} runs \"\n",
    "      f\"(converged: {converged_example.converged})\")\n",
    "print()\n",
    "\n",
    "# Show per-metric detail\n",
    "for s in converged_example.metric_statuses:\n",
    "    ci_lo = s.current_mean - s.ci_half_width\n",
    "    ci_hi = s.current_mean + s.ci_half_width\n",
    "    print(f\"  {s.metric.value}:\")\n",
    "    print(f\"    mean = {s.current_mean:.4f}  \"\n",
    "          f\"95% CI = [{ci_lo:.4f}, {ci_hi:.4f}]  \"\n",
    "          f\"rel_error = {s.relative_error:.4f}\")\n",
    "\n",
    "# Compare: the fixed 100-run result from earlier\n",
    "print()\n",
    "print(f\"For comparison, the fixed 100-run result had availability \"\n",
    "      f\"std = {results_with_replacement.availability_std()*100:.2f}% \"\n",
    "      f\"across only {len(results_with_replacement.availability_samples)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decimal-place accuracy with absolute error\n",
    "\n",
    "The examples above use `relative_error`, which bounds the CI half-width as a\n",
    "fraction of the mean (e.g., 5% of the mean). But if you want availability\n",
    "accurate to a specific number of **decimal places**, use `absolute_error` instead.\n",
    "\n",
    "| Desired accuracy | `absolute_error` value | Meaning |\n",
    "|---|---|---|\n",
    "| 1 decimal place on the fraction | `0.1` | mean ± 0.1 (e.g., 0.4 ± 0.1) |\n",
    "| 2 decimal places on the fraction | `0.01` | mean ± 0.01 (e.g., 0.45 ± 0.01) |\n",
    "| 1 decimal place on the percentage | `0.001` | mean ± 0.1% (e.g., 45.7% ± 0.1%) |\n",
    "| 2 decimal places on the percentage | `0.0001` | mean ± 0.01% (e.g., 45.74% ± 0.01%) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get availability accurate to 2 decimal places on the fraction (±0.01)\n",
    "# i.e. if the true mean is 0.4574, we want our estimate in [0.4474, 0.4674]\n",
    "\n",
    "result_2dp = run_monte_carlo_converged(\n",
    "    cluster_factory=lambda: create_cluster(5),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    max_time=days(365),\n",
    "    confidence_level=0.95,\n",
    "    absolute_error=0.01,  # ±0.01 on the availability fraction\n",
    "    metrics=[ConvergenceMetric.AVAILABILITY],\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    "    min_runs=30,\n",
    "    max_runs=10_000,\n",
    "    batch_size=50,\n",
    ")\n",
    "\n",
    "status = result_2dp.metric_statuses[0]\n",
    "mean = status.current_mean\n",
    "hw = status.ci_half_width\n",
    "\n",
    "print(f\"Runs needed: {result_2dp.total_runs}\")\n",
    "print(f\"Availability: {mean:.4f}  95% CI: [{mean - hw:.4f}, {mean + hw:.4f}]\")\n",
    "print(f\"CI half-width: ±{hw:.4f}  (target: ±0.0100)\")\n",
    "print(f\"Converged: {result_2dp.converged}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Mean Time to Data Loss (MTTDL) — Convergence\n",
    "\n",
    "To estimate **mean time to data loss** with a confidence interval, set\n",
    "`max_time=None` so each simulation runs indefinitely until data loss occurs.\n",
    "This guarantees every run contributes a sample, making convergence\n",
    "straightforward.\n",
    "\n",
    "The adaptive runner will keep adding batches until the CI on MTTDL is\n",
    "within the specified tolerance (relative or absolute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converge on mean time to data loss with 95% CI, 5% relative error.\n",
    "# max_time=None means each run continues until data loss — no truncation.\n",
    "\n",
    "mttdl_result = run_monte_carlo_converged(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    max_time=None,            # run each sim until data loss occurs\n",
    "    stop_on_data_loss=True,\n",
    "    confidence_level=0.95,\n",
    "    relative_error=0.05,      # CI half-width ≤ 5% of the mean\n",
    "    metrics=[ConvergenceMetric.MEAN_TIME_TO_DATA_LOSS],\n",
    "    seed=42,\n",
    "    min_runs=30,\n",
    "    max_runs=5000,\n",
    "    batch_size=20,\n",
    ")\n",
    "\n",
    "print(mttdl_result.summary())\n",
    "\n",
    "# Also available programmatically:\n",
    "mc = mttdl_result.results\n",
    "ci = mc.ci_time_to_actual_loss()\n",
    "if ci is not None:\n",
    "    print(f\"\\nMTTDL: {mc.mean_time_to_actual_loss() / 86400:.1f} days\")\n",
    "    print(f\"  95% CI: [{ci[0] / 86400:.1f}, {ci[1] / 86400:.1f}] days\")\n",
    "    print(f\"  Std:    {mc.std_time_to_actual_loss() / 86400:.1f} days\")\n",
    "    print(f\"  Runs:   {len(mc.time_to_actual_loss_samples_filtered())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results\n",
    "\n",
    "### 5.1 Availability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF histogram of availability\n",
    "avail_samples = [a * 100 for a in results_with_replacement.availability_samples]\n",
    "fig = make_pdf_histogram(\n",
    "    samples=avail_samples,\n",
    "    title=\"Availability Distribution (with Replacement Strategy)\",\n",
    "    x_label=\"Availability (%)\",\n",
    "    bins=30,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare availability between strategies\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=[results_no_op, results_with_replacement],\n",
    "    labels=[\"No Intervention\", \"With Replacement\"],\n",
    "    title=\"Availability Comparison: No Intervention vs Replacement Strategy\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Time to Data Loss Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDF of time to actual data loss (NoOp strategy)\n",
    "loss_times_days = [t / 86400 for t in results_no_op.time_to_actual_loss_samples_filtered()]\n",
    "\n",
    "if loss_times_days:\n",
    "    fig = make_cdf_plot(\n",
    "        samples=loss_times_days,\n",
    "        title=\"Time to Data Loss CDF (No Intervention)\",\n",
    "        x_label=\"Days\",\n",
    "        show_percentiles=[50, 90, 99],\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data loss events occurred in the simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF histogram of time to data loss\n",
    "if loss_times_days:\n",
    "    fig = make_pdf_histogram(\n",
    "        samples=loss_times_days,\n",
    "        title=\"Time to Data Loss PDF (No Intervention)\",\n",
    "        x_label=\"Days\",\n",
    "        bins=30,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parameter Sensitivity Analysis\n",
    "\n",
    "Let's see how the number of nodes affects availability and time to data loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 3, 5, and 7 node clusters\n",
    "results_by_size = {}\n",
    "\n",
    "for num_nodes in [3, 5, 7]:\n",
    "    results = run_monte_carlo(\n",
    "        cluster_factory=lambda n=num_nodes: create_cluster(n),\n",
    "        strategy_factory=make_replacement_strategy,\n",
    "        protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "        num_simulations=50,\n",
    "        max_time=days(365),\n",
    "        stop_on_data_loss=True,\n",
    "        seed=42,\n",
    "    )\n",
    "    results_by_size[num_nodes] = results\n",
    "    print(f\"\\n{num_nodes}-node cluster:\")\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare availability across cluster sizes\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=list(results_by_size.values()),\n",
    "    labels=[f\"{n} nodes\" for n in results_by_size.keys()],\n",
    "    title=\"Availability by Cluster Size\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare time to data loss across cluster sizes\n",
    "fig = make_time_to_loss_comparison(\n",
    "    results_list=list(results_by_size.values()),\n",
    "    labels=[f\"{n} nodes\" for n in results_by_size.keys()],\n",
    "    title=\"Time to Data Loss by Cluster Size\",\n",
    "    actual=True,\n",
    "    time_unit=\"days\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Failure Scenarios\n",
    "\n",
    "Let's simulate a scenario with unreliable nodes (higher failure rates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unreliable_node_config(region: str = \"us-east\") -> NodeConfig:\n",
    "    \"\"\"Node with higher failure rates.\"\"\"\n",
    "    return NodeConfig(\n",
    "        region=region,\n",
    "        cost_per_hour=0.30,  # Cheaper but less reliable\n",
    "        # Transient failures: ~1 per day\n",
    "        failure_dist=Exponential(rate=1 / days(1)),\n",
    "        # Recovery time: 10-30 minutes (slower recovery)\n",
    "        recovery_dist=Uniform(low=minutes(10), high=minutes(30)),\n",
    "        # Permanent data loss: ~1 per 6 months\n",
    "        data_loss_dist=Exponential(rate=1 / days(180)),\n",
    "        log_replay_rate_dist=Constant(2.0),  # Slower log replay\n",
    "        snapshot_download_time_dist=Constant(minutes(10)),  # Slower snapshot download\n",
    "        spawn_dist=Uniform(low=minutes(15), high=minutes(30)),\n",
    "    )\n",
    "\n",
    "def create_unreliable_cluster(num_nodes: int = 5) -> ClusterState:\n",
    "    nodes = {}\n",
    "    for i in range(num_nodes):\n",
    "        config = make_unreliable_node_config()\n",
    "        nodes[f\"node{i}\"] = NodeState(\n",
    "            node_id=f\"node{i}\",\n",
    "            config=config,\n",
    "        )\n",
    "    return ClusterState(\n",
    "        nodes=nodes,\n",
    "        network=NetworkState(),\n",
    "        target_cluster_size=num_nodes,\n",
    "    )\n",
    "\n",
    "# Run simulation with unreliable nodes\n",
    "results_unreliable = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_unreliable_cluster(5),\n",
    "    strategy_factory=lambda: SimpleReplacementStrategy(\n",
    "        default_node_config=make_unreliable_node_config(),\n",
    "    ),\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"Unreliable 5-node cluster:\")\n",
    "print(results_unreliable.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare reliable vs unreliable clusters\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=[results_by_size[5], results_unreliable],\n",
    "    labels=[\"Reliable 5-node\", \"Unreliable 5-node\"],\n",
    "    title=\"Reliable vs Unreliable Nodes\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Protocol Comparison: Leaderless vs Raft\n",
    "\n",
    "The simulator supports three consensus protocol models with different availability semantics:\n",
    "\n",
    "- **LeaderlessUpToDateQuorumProtocol**: Any node can propose; requires a quorum of *up-to-date* nodes to commit (e.g., EPaxos, multi-decree Paxos).\n",
    "- **LeaderlessMajorityAvailableProtocol**: Any node can propose; requires a quorum of *available* nodes, even if they are lagging behind (e.g., eventually-consistent systems). More permissive — lagging replicas can still participate.\n",
    "- **RaftLikeProtocol**: A single leader accepts writes; if the leader fails, an election occurs and the system is **unavailable for the duration of the election**. Requires leader + quorum of up-to-date nodes (e.g., Raft, Multi-Paxos with a stable leader).\n",
    "\n",
    "The key tradeoff: Raft-like protocols pay an availability cost during leader elections, but the leaderless up-to-date quorum protocol requires *all* quorum members to be fully caught up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Monte Carlo for each protocol with the same cluster & strategy\n",
    "protocols = {\n",
    "    \"Leaderless (up-to-date quorum)\": LeaderlessUpToDateQuorumProtocol(),\n",
    "    \"Leaderless (majority available)\": LeaderlessMajorityAvailableProtocol(),\n",
    "    \"Raft-like (3-8s election)\": RaftLikeProtocol(\n",
    "        election_time_dist=Uniform(low=Seconds(3), high=Seconds(8)),\n",
    "    ),\n",
    "}\n",
    "\n",
    "protocol_results = {}\n",
    "for label, protocol in protocols.items():\n",
    "    result = run_monte_carlo(\n",
    "        cluster_factory=lambda: create_cluster(3),\n",
    "        strategy_factory=make_node_replacement_strategy,\n",
    "        protocol=protocol,\n",
    "        num_simulations=100,\n",
    "        max_time=days(365),\n",
    "        stop_on_data_loss=True,\n",
    "        seed=42,\n",
    "    )\n",
    "    protocol_results[label] = result\n",
    "    print(f\"\\n{label}:\")\n",
    "    print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare availability across protocols\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=list(protocol_results.values()),\n",
    "    labels=list(protocol_results.keys()),\n",
    "    title=\"Availability by Consensus Protocol\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay time-to-data-loss CDFs across protocols\n",
    "loss_samples = []\n",
    "loss_labels = []\n",
    "for label, result in protocol_results.items():\n",
    "    samples = [t / 86400 for t in result.time_to_actual_loss_samples_filtered()]\n",
    "    if samples:\n",
    "        loss_samples.append(samples)\n",
    "        loss_labels.append(label)\n",
    "\n",
    "if loss_samples:\n",
    "    fig = make_multi_cdf_plot(\n",
    "        samples_list=loss_samples,\n",
    "        labels=loss_labels,\n",
    "        title=\"Time to Data Loss CDF — Protocol Comparison\",\n",
    "        x_label=\"Days\",\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data loss events to compare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Network Partition Simulation\n",
    "\n",
    "Real distributed systems face **network partitions** in addition to node failures.\n",
    "The simulator supports region-level network outages via `NetworkConfig`:\n",
    "\n",
    "- **outage_dist**: Distribution for time between network outage events\n",
    "- **outage_duration_dist**: Distribution for how long each outage lasts\n",
    "- **affected_regions**: Which regions can experience full network outages\n",
    "\n",
    "When a region's network is down, all nodes in that region become **effectively unavailable**\n",
    "for quorum purposes — even though the nodes themselves haven't crashed. This can cause\n",
    "quorum loss if multiple nodes share a region, and forces nodes to re-sync when the\n",
    "partition heals (since they fall behind on commits during the outage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a network configuration with periodic regional outages\n",
    "network_config = NetworkConfig(\n",
    "    outage_dist=Exponential(rate=1 / days(30)),  # ~1 outage per month per region\n",
    "    outage_duration_dist=Uniform(low=minutes(10), high=hours(2)),  # 10min–2hr outages\n",
    "    affected_regions=[\"us-east\", \"us-west\", \"eu-central\"],\n",
    ")\n",
    "\n",
    "# Run with network partitions enabled\n",
    "results_with_partitions = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_node_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    "    network_config=network_config,\n",
    ")\n",
    "\n",
    "print(\"With network partitions (~monthly per region, 10min-2hr):\")\n",
    "print(results_with_partitions.summary())\n",
    "print(\"\\nWithout network partitions (for comparison):\")\n",
    "print(results_node_replacement.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare availability with and without network partitions\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=[results_node_replacement, results_with_partitions],\n",
    "    labels=[\"Node failures only\", \"Node failures + network partitions\"],\n",
    "    title=\"Impact of Network Partitions on Availability\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single run with event logging to see network events in action\n",
    "cluster = create_cluster(3)\n",
    "simulator = Simulator(\n",
    "    initial_cluster=cluster,\n",
    "    strategy=make_node_replacement_strategy(),\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    network_config=network_config,\n",
    "    seed=42,\n",
    "    log_events=True,\n",
    ")\n",
    "\n",
    "result = simulator.run_for(days(365))\n",
    "print(f\"End reason: {result.end_reason}\")\n",
    "print(f\"Availability: {result.metrics.availability_fraction() * 100:.2f}%\")\n",
    "\n",
    "# Show network-related events\n",
    "print(\"\\nNetwork events:\")\n",
    "for event in result.event_log:\n",
    "    if event.event_type in (EventType.NETWORK_OUTAGE_START, EventType.NETWORK_OUTAGE_END):\n",
    "        region = event.metadata.get(\"region\", event.target_id)\n",
    "        print(f\"  t={event.time/86400:.2f}d: {event.event_type.value} — {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Snapshot Interval & Commit Rate Sensitivity\n",
    "\n",
    "Protocols have two key parameters that affect **node recovery time**:\n",
    "\n",
    "- **commit_rate**: How fast data is committed (data units per second of wall time). A higher commit rate means nodes fall further behind during failures and take longer to catch up.\n",
    "- **snapshot_interval**: How often nodes take snapshots (in commit-index units). With snapshots, a lagging node can download a snapshot instead of replaying the entire log from the beginning — but it pays a fixed download cost.\n",
    "\n",
    "The recovery model works as follows:\n",
    "1. If the lagging node is behind the donor's last snapshot, it must **download the snapshot** first, then replay the remaining log suffix.\n",
    "2. If the node is ahead of the donor's snapshot, it replays the log directly.\n",
    "3. During recovery, new commits keep arriving at `commit_rate`, so the net catch-up rate is `(log_replay_rate - commit_rate)`. If the commit rate exceeds the replay rate, the node **can never catch up**.\n",
    "\n",
    "Let's see how these parameters affect availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different commit rates\n",
    "# Higher commit rates mean nodes fall further behind during downtime\n",
    "# Recall: node log_replay_rate is 3.0 units/s, so commit_rate must be < 3.0 to catch up\n",
    "\n",
    "commit_rate_configs = {\n",
    "    \"commit_rate=0.5 (low load)\": LeaderlessUpToDateQuorumProtocol(commit_rate=0.5),\n",
    "    \"commit_rate=1.0 (default)\": LeaderlessUpToDateQuorumProtocol(commit_rate=1.0),\n",
    "    \"commit_rate=2.5 (high load)\": LeaderlessUpToDateQuorumProtocol(commit_rate=2.5),\n",
    "}\n",
    "\n",
    "commit_rate_results = {}\n",
    "for label, protocol in commit_rate_configs.items():\n",
    "    result = run_monte_carlo(\n",
    "        cluster_factory=lambda: create_cluster(3),\n",
    "        strategy_factory=make_node_replacement_strategy,\n",
    "        protocol=protocol,\n",
    "        num_simulations=100,\n",
    "        max_time=days(365),\n",
    "        stop_on_data_loss=True,\n",
    "        seed=42,\n",
    "    )\n",
    "    commit_rate_results[label] = result\n",
    "    print(f\"\\n{label}:\")\n",
    "    print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_availability_boxplot(\n",
    "    results_list=list(commit_rate_results.values()),\n",
    "    labels=list(commit_rate_results.keys()),\n",
    "    title=\"Availability by Commit Rate (log_replay_rate=3.0)\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare snapshot intervals\n",
    "# With snapshot_interval=0, there is no log truncation — a lagging node replays the full log.\n",
    "# With snapshots, the node downloads a snapshot and then replays only the suffix.\n",
    "\n",
    "snapshot_configs = {\n",
    "    \"No snapshots\": LeaderlessUpToDateQuorumProtocol(\n",
    "        commit_rate=1.0, snapshot_interval=0,\n",
    "    ),\n",
    "    \"Snapshot every 3600 units\": LeaderlessUpToDateQuorumProtocol(\n",
    "        commit_rate=1.0, snapshot_interval=3600,\n",
    "    ),\n",
    "    \"Snapshot every 600 units\": LeaderlessUpToDateQuorumProtocol(\n",
    "        commit_rate=1.0, snapshot_interval=600,\n",
    "    ),\n",
    "}\n",
    "\n",
    "snapshot_results = {}\n",
    "for label, protocol in snapshot_configs.items():\n",
    "    result = run_monte_carlo(\n",
    "        cluster_factory=lambda: create_cluster(3),\n",
    "        strategy_factory=make_node_replacement_strategy,\n",
    "        protocol=protocol,\n",
    "        num_simulations=100,\n",
    "        max_time=days(365),\n",
    "        stop_on_data_loss=True,\n",
    "        seed=42,\n",
    "    )\n",
    "    snapshot_results[label] = result\n",
    "    print(f\"\\n{label}:\")\n",
    "    print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_availability_boxplot(\n",
    "    results_list=list(snapshot_results.values()),\n",
    "    labels=list(snapshot_results.keys()),\n",
    "    title=\"Availability by Snapshot Interval\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cost Analysis\n",
    "\n",
    "The simulator tracks infrastructure costs throughout each run. Every node\n",
    "(including nodes being provisioned) is billed at its `cost_per_hour` rate.\n",
    "Replacement strategies that spawn new nodes increase total cost, while\n",
    "strategies that scale down reduce it.\n",
    "\n",
    "Let's visualize how costs vary across different configurations and strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost distribution: NoOp vs SimpleReplacement vs NodeReplacement\n",
    "fig = make_pdf_histogram(\n",
    "    samples=results_no_op.cost_samples,\n",
    "    title=\"Cost Distribution — No Intervention (3-node, 1 year)\",\n",
    "    x_label=\"Total Cost ($)\",\n",
    "    bins=30,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = make_pdf_histogram(\n",
    "    samples=results_node_replacement.cost_samples,\n",
    "    title=\"Cost Distribution — Node Replacement Strategy (3-node, 1 year)\",\n",
    "    x_label=\"Total Cost ($)\",\n",
    "    bins=30,\n",
    "    color=\"coral\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay cost CDFs across strategies for direct comparison\n",
    "cost_samples_list = [\n",
    "    results_no_op.cost_samples,\n",
    "    results_with_replacement.cost_samples,\n",
    "    results_node_replacement.cost_samples,\n",
    "]\n",
    "cost_labels = [\n",
    "    f\"No Intervention (mean=${results_no_op.cost_mean():,.0f})\",\n",
    "    f\"Simple Replacement (mean=${results_with_replacement.cost_mean():,.0f})\",\n",
    "    f\"Node Replacement (mean=${results_node_replacement.cost_mean():,.0f})\",\n",
    "]\n",
    "\n",
    "fig = make_multi_cdf_plot(\n",
    "    samples_list=cost_samples_list,\n",
    "    labels=cost_labels,\n",
    "    title=\"Cost CDF — Strategy Comparison (3-node, 1 year)\",\n",
    "    x_label=\"Total Cost ($)\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost vs availability tradeoff across cluster sizes\n",
    "print(f\"{'Config':<25} {'Availability':>14} {'Mean Cost':>12} {'Cost/9':>10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for num_nodes, result in results_by_size.items():\n",
    "    avail = result.availability_mean()\n",
    "    cost = result.cost_mean()\n",
    "    nines = -np.log10(1 - avail) if avail < 1.0 else float(\"inf\")\n",
    "    cost_per_nine = cost / nines if nines > 0 and nines != float(\"inf\") else float(\"nan\")\n",
    "    print(\n",
    "        f\"{num_nodes}-node cluster{'':<13} \"\n",
    "        f\"{avail*100:>13.2f}% \"\n",
    "        f\"${cost:>10,.0f} \"\n",
    "        f\"${cost_per_nine:>8,.0f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This simulator allows you to:\n",
    "\n",
    "1. **Model RSM deployments** with realistic node configurations\n",
    "2. **Define failure distributions** (exponential, Weibull, uniform, etc.)\n",
    "3. **Compare consensus protocols** — leaderless (up-to-date quorum, majority available) and leader-based (Raft-like with election downtime)\n",
    "4. **Simulate network partitions** — region-level outages that make nodes unavailable without crashing them\n",
    "5. **Tune protocol parameters** — commit rate and snapshot interval to understand recovery dynamics\n",
    "6. **Implement custom strategies** for handling failures (no-op, simple replacement, timeout-based replacement)\n",
    "7. **Run Monte Carlo simulations** with fixed sample sizes or adaptive convergence for high-confidence results\n",
    "8. **Analyze costs** — infrastructure cost distributions and cost/availability tradeoffs\n",
    "9. **Visualize results** with PDFs, CDFs, box plots, multi-CDF overlays, and comparison charts\n",
    "\n",
    "Key metrics computed:\n",
    "- **Availability**: Fraction of time the system can accept commits\n",
    "- **Time to potential data loss**: When quorum is first lost\n",
    "- **Time to actual data loss**: When all up-to-date nodes fail\n",
    "- **Total cost**: Accumulated infrastructure costs (including provisioning)\n",
    "- **Cost per nine**: Dollar cost for each nine of availability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
