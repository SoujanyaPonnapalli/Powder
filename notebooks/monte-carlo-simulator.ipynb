{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo RSM Simulator\n",
    "\n",
    "This notebook demonstrates how to use the Monte Carlo simulator to analyze RSM (Replicated State Machine) deployments. We'll explore:\n",
    "\n",
    "1. Setting up node configurations with failure distributions\n",
    "2. Running single simulations\n",
    "3. Running Monte Carlo simulations for statistical analysis\n",
    "4. Visualizing availability and time-to-data-loss distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from powder.simulation import (\n",
    "    # Time units\n",
    "    Seconds, hours, days, minutes,\n",
    "    # Distributions\n",
    "    Exponential, Weibull, Normal, Uniform, Constant,\n",
    "    # Node\n",
    "    NodeConfig, NodeState,\n",
    "    # Network\n",
    "    RegionPair, NetworkConfig, NetworkState,\n",
    "    # Cluster\n",
    "    ClusterState,\n",
    "    # Strategy\n",
    "    NoOpStrategy, SimpleReplacementStrategy,\n",
    "    # Simulator\n",
    "    Simulator,\n",
    ")\n",
    "from powder.monte_carlo import run_monte_carlo, MonteCarloConfig, MonteCarloRunner\n",
    "from powder.graphing_utils import (\n",
    "    make_pdf_histogram,\n",
    "    make_cdf_plot,\n",
    "    make_availability_boxplot,\n",
    "    make_time_to_loss_comparison,\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Node Configuration\n",
    "\n",
    "Each node has:\n",
    "- **region**: Geographic location\n",
    "- **cost_per_hour**: Dollar cost to run the node\n",
    "- **failure_dist**: Distribution for time until transient failure\n",
    "- **recovery_dist**: Distribution for time to recover from failure\n",
    "- **data_loss_dist**: Distribution for time until permanent data loss (e.g., disk failure)\n",
    "- **sync_rate_dist**: Distribution for sync rate (seconds of data per second of real time)\n",
    "- **spawn_dist**: Distribution for time to spawn a new replacement node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic node configuration\n",
    "def make_standard_node_config(region: str = \"us-east\") -> NodeConfig:\n",
    "    return NodeConfig(\n",
    "        region=region,\n",
    "        cost_per_hour=0.50,  # $0.50/hour per node\n",
    "        # Transient failures: ~1 per week on average\n",
    "        failure_dist=Exponential(rate=1 / days(7)),\n",
    "        # Recovery time: 5-15 minutes\n",
    "        recovery_dist=Uniform(low=minutes(5), high=minutes(15)),\n",
    "        # Permanent data loss: ~1 per year (disk failure rate)\n",
    "        data_loss_dist=Exponential(rate=1 / days(365)),\n",
    "        # Sync rate: node can download 3 seconds of data per 1 second of real time\n",
    "        sync_rate_dist=Constant(3.0),\n",
    "        # Spawn time: 10-20 minutes to provision a new node\n",
    "        spawn_dist=Uniform(low=minutes(10), high=minutes(20)),\n",
    "    )\n",
    "\n",
    "node_config = make_standard_node_config()\n",
    "print(f\"Node config: {node_config.region}, ${node_config.cost_per_hour}/hr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Initial Cluster\n",
    "\n",
    "A cluster consists of multiple nodes. For a 3-node cluster, we need a quorum of 2 nodes to commit new requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster(num_nodes: int = 3, regions: list[str] | None = None) -> ClusterState:\n",
    "    \"\"\"Create a fresh cluster with the specified number of nodes.\"\"\"\n",
    "    if regions is None:\n",
    "        regions = [\"us-east\", \"us-west\", \"eu-west\"]\n",
    "    \n",
    "    nodes = {}\n",
    "    for i in range(num_nodes):\n",
    "        region = regions[i % len(regions)]\n",
    "        config = make_standard_node_config(region)\n",
    "        nodes[f\"node{i}\"] = NodeState(\n",
    "            node_id=f\"node{i}\",\n",
    "            config=config,\n",
    "            last_up_to_date_time=Seconds(0),\n",
    "        )\n",
    "    \n",
    "    return ClusterState(\n",
    "        nodes=nodes,\n",
    "        network=NetworkState(),\n",
    "        target_cluster_size=num_nodes,\n",
    "    )\n",
    "\n",
    "cluster = create_cluster(3)\n",
    "print(f\"Created cluster: {cluster}\")\n",
    "print(f\"Quorum size: {cluster.quorum_size()}\")\n",
    "print(f\"Can commit: {cluster.can_commit()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run a Single Simulation\n",
    "\n",
    "Let's run a simulation for 30 days and observe the behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation for 30 days with no intervention strategy\n",
    "cluster = create_cluster(3)\n",
    "simulator = Simulator(\n",
    "    initial_cluster=cluster,\n",
    "    strategy=NoOpStrategy(),\n",
    "    seed=42,\n",
    "    log_events=True,  # Keep event log for debugging\n",
    ")\n",
    "\n",
    "result = simulator.run_for(days(30))\n",
    "\n",
    "print(f\"Simulation ended: {result.end_reason}\")\n",
    "print(f\"End time: {result.end_time / 86400:.2f} days\")\n",
    "print(f\"Availability: {result.metrics.availability_fraction() * 100:.2f}%\")\n",
    "print(f\"Total cost: ${result.metrics.total_cost:.2f}\")\n",
    "print(f\"Events processed: {len(result.event_log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 10 events\n",
    "print(\"First 10 events:\")\n",
    "for event in result.event_log[:10]:\n",
    "    print(f\"  t={event.time/3600:.2f}h: {event.event_type.value} on {event.target_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Monte Carlo Simulations\n",
    "\n",
    "To get statistical properties, we run many simulations and aggregate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 100 simulations, each for 1 year, with NoOp strategy\n",
    "results_no_op = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=NoOpStrategy,\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(results_no_op.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run with SimpleReplacementStrategy that spawns replacements for failed nodes\n",
    "def make_replacement_strategy():\n",
    "    return SimpleReplacementStrategy(\n",
    "        default_node_config=make_standard_node_config(),\n",
    "        scale_down_threshold=3,  # Only scale down if 3+ nodes fail simultaneously\n",
    "    )\n",
    "\n",
    "results_with_replacement = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(results_with_replacement.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results\n",
    "\n",
    "### 5.1 Availability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF histogram of availability\n",
    "avail_samples = [a * 100 for a in results_with_replacement.availability_samples]\n",
    "fig = make_pdf_histogram(\n",
    "    samples=avail_samples,\n",
    "    title=\"Availability Distribution (with Replacement Strategy)\",\n",
    "    x_label=\"Availability (%)\",\n",
    "    bins=30,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare availability between strategies\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=[results_no_op, results_with_replacement],\n",
    "    labels=[\"No Intervention\", \"With Replacement\"],\n",
    "    title=\"Availability Comparison: No Intervention vs Replacement Strategy\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Time to Data Loss Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDF of time to actual data loss (NoOp strategy)\n",
    "loss_times_days = [t / 86400 for t in results_no_op.time_to_actual_loss_samples_filtered()]\n",
    "\n",
    "if loss_times_days:\n",
    "    fig = make_cdf_plot(\n",
    "        samples=loss_times_days,\n",
    "        title=\"Time to Data Loss CDF (No Intervention)\",\n",
    "        x_label=\"Days\",\n",
    "        show_percentiles=[50, 90, 99],\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data loss events occurred in the simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF histogram of time to data loss\n",
    "if loss_times_days:\n",
    "    fig = make_pdf_histogram(\n",
    "        samples=loss_times_days,\n",
    "        title=\"Time to Data Loss PDF (No Intervention)\",\n",
    "        x_label=\"Days\",\n",
    "        bins=30,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parameter Sensitivity Analysis\n",
    "\n",
    "Let's see how the number of nodes affects availability and time to data loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 3, 5, and 7 node clusters\n",
    "results_by_size = {}\n",
    "\n",
    "for num_nodes in [3, 5, 7]:\n",
    "    results = run_monte_carlo(\n",
    "        cluster_factory=lambda n=num_nodes: create_cluster(n),\n",
    "        strategy_factory=make_replacement_strategy,\n",
    "        num_simulations=50,\n",
    "        max_time=days(365),\n",
    "        stop_on_data_loss=True,\n",
    "        seed=42,\n",
    "    )\n",
    "    results_by_size[num_nodes] = results\n",
    "    print(f\"\\n{num_nodes}-node cluster:\")\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare availability across cluster sizes\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=list(results_by_size.values()),\n",
    "    labels=[f\"{n} nodes\" for n in results_by_size.keys()],\n",
    "    title=\"Availability by Cluster Size\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare time to data loss across cluster sizes\n",
    "fig = make_time_to_loss_comparison(\n",
    "    results_list=list(results_by_size.values()),\n",
    "    labels=[f\"{n} nodes\" for n in results_by_size.keys()],\n",
    "    title=\"Time to Data Loss by Cluster Size\",\n",
    "    actual=True,\n",
    "    time_unit=\"days\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Failure Scenarios\n",
    "\n",
    "Let's simulate a scenario with unreliable nodes (higher failure rates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unreliable_node_config(region: str = \"us-east\") -> NodeConfig:\n",
    "    \"\"\"Node with higher failure rates.\"\"\"\n",
    "    return NodeConfig(\n",
    "        region=region,\n",
    "        cost_per_hour=0.30,  # Cheaper but less reliable\n",
    "        # Transient failures: ~1 per day\n",
    "        failure_dist=Exponential(rate=1 / days(1)),\n",
    "        # Recovery time: 10-30 minutes (slower recovery)\n",
    "        recovery_dist=Uniform(low=minutes(10), high=minutes(30)),\n",
    "        # Permanent data loss: ~1 per 6 months\n",
    "        data_loss_dist=Exponential(rate=1 / days(180)),\n",
    "        sync_rate_dist=Constant(2.0),  # Slower sync\n",
    "        spawn_dist=Uniform(low=minutes(15), high=minutes(30)),\n",
    "    )\n",
    "\n",
    "def create_unreliable_cluster(num_nodes: int = 5) -> ClusterState:\n",
    "    nodes = {}\n",
    "    for i in range(num_nodes):\n",
    "        config = make_unreliable_node_config()\n",
    "        nodes[f\"node{i}\"] = NodeState(\n",
    "            node_id=f\"node{i}\",\n",
    "            config=config,\n",
    "        )\n",
    "    return ClusterState(\n",
    "        nodes=nodes,\n",
    "        network=NetworkState(),\n",
    "        target_cluster_size=num_nodes,\n",
    "    )\n",
    "\n",
    "# Run simulation with unreliable nodes\n",
    "results_unreliable = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_unreliable_cluster(5),\n",
    "    strategy_factory=lambda: SimpleReplacementStrategy(\n",
    "        default_node_config=make_unreliable_node_config(),\n",
    "    ),\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"Unreliable 5-node cluster:\")\n",
    "print(results_unreliable.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare reliable vs unreliable clusters\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=[results_by_size[5], results_unreliable],\n",
    "    labels=[\"Reliable 5-node\", \"Unreliable 5-node\"],\n",
    "    title=\"Reliable vs Unreliable Nodes\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This simulator allows you to:\n",
    "\n",
    "1. **Model RSM deployments** with realistic node configurations\n",
    "2. **Define failure distributions** (exponential, Weibull, uniform, etc.)\n",
    "3. **Implement custom strategies** for handling failures\n",
    "4. **Run Monte Carlo simulations** to get statistical results\n",
    "5. **Visualize results** with PDFs, CDFs, and comparison plots\n",
    "\n",
    "Key metrics computed:\n",
    "- **Availability**: Fraction of time the system can accept commits\n",
    "- **Time to potential data loss**: When quorum is first lost\n",
    "- **Time to actual data loss**: When all up-to-date nodes fail\n",
    "- **Total cost**: Accumulated infrastructure costs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
