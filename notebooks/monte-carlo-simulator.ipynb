{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo RSM Simulator\n",
    "\n",
    "This notebook demonstrates how to use the Monte Carlo simulator to analyze RSM (Replicated State Machine) deployments. We'll explore:\n",
    "\n",
    "1. Setting up node configurations with failure distributions\n",
    "2. Running single simulations\n",
    "3. Running Monte Carlo simulations for statistical analysis\n",
    "4. Visualizing availability and time-to-data-loss distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from powder.simulation import (\n",
    "    # Time units\n",
    "    Seconds, hours, days, minutes,\n",
    "    # Distributions\n",
    "    Exponential, Weibull, Normal, Uniform, Constant,\n",
    "    # Node\n",
    "    NodeConfig, NodeState,\n",
    "    # Network\n",
    "    NetworkConfig, NetworkState,\n",
    "    # Cluster\n",
    "    ClusterState,\n",
    "    # Strategy\n",
    "    NoOpStrategy, SimpleReplacementStrategy,\n",
    "    # Protocol\n",
    "    LeaderlessUpToDateQuorumProtocol, RaftLikeProtocol,\n",
    "    # Simulator\n",
    "    Simulator,\n",
    ")\n",
    "from powder.monte_carlo import (\n",
    "    run_monte_carlo, MonteCarloConfig, MonteCarloRunner,\n",
    "    run_monte_carlo_converged, ConvergenceCriteria, ConvergenceMetric,\n",
    "    estimate_required_runs,\n",
    ")\n",
    "from powder.graphing_utils import (\n",
    "    make_pdf_histogram,\n",
    "    make_cdf_plot,\n",
    "    make_availability_boxplot,\n",
    "    make_time_to_loss_comparison,\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Node Configuration\n",
    "\n",
    "Each node has:\n",
    "- **region**: Geographic location\n",
    "- **cost_per_hour**: Dollar cost to run the node\n",
    "- **failure_dist**: Distribution for time until transient failure\n",
    "- **recovery_dist**: Distribution for time to recover from failure\n",
    "- **data_loss_dist**: Distribution for time until permanent data loss (e.g., disk failure)\n",
    "- **log_replay_rate_dist**: Distribution for log replay rate (committed-data units replayed per second of wall time)\n",
    "- **snapshot_download_time_dist**: Distribution for wall-clock time to download a full snapshot\n",
    "- **spawn_dist**: Distribution for time to spawn a new replacement node\n",
    "\n",
    "Snapshot interval and commit rate are configured on the Protocol, not on individual nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic node configuration\n",
    "def make_standard_node_config(region: str = \"us-east\") -> NodeConfig:\n",
    "    return NodeConfig(\n",
    "        region=region,\n",
    "        cost_per_hour=0.50,  # $0.50/hour per node\n",
    "        # Transient failures: ~1 per week on average\n",
    "        failure_dist=Exponential(rate=1 / days(7)),\n",
    "        # Recovery time: 5-15 minutes\n",
    "        recovery_dist=Uniform(low=minutes(5), high=minutes(15)),\n",
    "        # Permanent data loss: ~1 per year (disk failure rate)\n",
    "        data_loss_dist=Exponential(rate=1 / days(365)),\n",
    "        # Log replay rate: node can replay 3 units of committed data per 1 second of wall time\n",
    "        log_replay_rate_dist=Constant(3.0),\n",
    "        # Snapshot download time: 5 minutes to download a full snapshot\n",
    "        snapshot_download_time_dist=Constant(minutes(5)),\n",
    "        # Spawn time: 10-20 minutes to provision a new node\n",
    "        spawn_dist=Uniform(low=minutes(1), high=minutes(5)),\n",
    "    )\n",
    "\n",
    "node_config = make_standard_node_config()\n",
    "print(f\"Node config: {node_config.region}, ${node_config.cost_per_hour}/hr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Initial Cluster\n",
    "\n",
    "A cluster consists of multiple nodes. For a 3-node cluster, we need a quorum of 2 nodes to commit new requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster(num_nodes: int = 3, regions: list[str] | None = None) -> ClusterState:\n",
    "    \"\"\"Create a fresh cluster with the specified number of nodes.\"\"\"\n",
    "    if regions is None:\n",
    "        regions = [\"us-east\", \"us-west\", \"eu-central\"]\n",
    "    \n",
    "    nodes = {}\n",
    "    for i in range(num_nodes):\n",
    "        region = regions[i % len(regions)]\n",
    "        config = make_standard_node_config(region)\n",
    "        nodes[f\"node{i}\"] = NodeState(\n",
    "            node_id=f\"node{i}\",\n",
    "            config=config,\n",
    "        )\n",
    "    \n",
    "    return ClusterState(\n",
    "        nodes=nodes,\n",
    "        network=NetworkState(),\n",
    "        target_cluster_size=num_nodes,\n",
    "    )\n",
    "\n",
    "cluster = create_cluster(3)\n",
    "print(f\"Created cluster: {cluster}\")\n",
    "print(f\"Quorum size: {cluster.quorum_size()}\")\n",
    "print(f\"Can commit: {cluster.can_commit()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run a Single Simulation\n",
    "\n",
    "Let's run a simulation for 30 days and observe the behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation for 30 days with no intervention strategy\n",
    "cluster = create_cluster(3)\n",
    "simulator = Simulator(\n",
    "    initial_cluster=cluster,\n",
    "    strategy=NoOpStrategy(),\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    seed=42,\n",
    "    log_events=True,  # Keep event log for debugging\n",
    ")\n",
    "\n",
    "result = simulator.run_for(days(30))\n",
    "\n",
    "print(f\"Simulation ended: {result.end_reason}\")\n",
    "print(f\"End time: {result.end_time / 86400:.2f} days\")\n",
    "print(f\"Availability: {result.metrics.availability_fraction() * 100:.2f}%\")\n",
    "print(f\"Total cost: ${result.metrics.total_cost:.2f}\")\n",
    "print(f\"Events processed: {len(result.event_log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 10 events\n",
    "print(\"First 10 events:\")\n",
    "for event in result.event_log[:10]:\n",
    "    print(f\"  t={event.time/3600:.2f}h: {event.event_type.value} on {event.target_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Monte Carlo Simulations\n",
    "\n",
    "To get statistical properties, we run many simulations and aggregate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 100 simulations, each for 1 year, with NoOp strategy\n",
    "results_no_op = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=NoOpStrategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(results_no_op.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run with SimpleReplacementStrategy that spawns replacements for failed nodes\n",
    "def make_replacement_strategy():\n",
    "    return SimpleReplacementStrategy(\n",
    "        default_node_config=make_standard_node_config(),\n",
    "        scale_down_threshold=3,  # Only scale down if 3+ nodes fail simultaneously\n",
    "    )\n",
    "\n",
    "results_with_replacement = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(results_with_replacement.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. Adaptive Monte Carlo — Automatic Sample Size\n",
    "\n",
    "Instead of guessing how many simulations to run, we can let the runner\n",
    "automatically determine the required number of runs to achieve a desired\n",
    "confidence level and relative error on key metrics.\n",
    "\n",
    "The runner works in two phases:\n",
    "1. **Pilot batch**: Runs `min_runs` simulations to estimate variance.\n",
    "2. **Adaptive batches**: Uses the t-distribution CI formula `n = (t * σ / (ε * μ))²`\n",
    "   to estimate how many more runs are needed, running them in batches until all\n",
    "   target metrics converge or `max_runs` is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run adaptive Monte Carlo — converge on availability with 95% CI, 5% relative error\n",
    "converged_result = run_monte_carlo_converged(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    max_time=days(365),\n",
    "    confidence_level=0.95,\n",
    "    relative_error=0.05,  # CI half-width <= 5% of the mean\n",
    "    metrics=[ConvergenceMetric.AVAILABILITY],\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    "    min_runs=30,\n",
    "    max_runs=5000,\n",
    "    batch_size=20,\n",
    ")\n",
    "\n",
    "print(converged_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converge on multiple metrics simultaneously\n",
    "# The runner will keep going until ALL specified metrics are within tolerance.\n",
    "converged_multi = run_monte_carlo_converged(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    max_time=days(365),\n",
    "    confidence_level=0.95,\n",
    "    relative_error=0.05,\n",
    "    metrics=[\n",
    "        ConvergenceMetric.AVAILABILITY,\n",
    "        ConvergenceMetric.COST,\n",
    "        ConvergenceMetric.DATA_LOSS_PROBABILITY,\n",
    "    ],\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    "    min_runs=30,\n",
    "    max_runs=5000,\n",
    "    batch_size=20,\n",
    ")\n",
    "\n",
    "print(converged_multi.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also estimate required runs from a small pilot before committing\n",
    "# to a full adaptive run. This is useful for planning compute budgets.\n",
    "pilot = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_cluster(3),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=30,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "estimates = estimate_required_runs(\n",
    "    pilot,\n",
    "    ConvergenceCriteria(\n",
    "        confidence_level=0.95,\n",
    "        relative_error=0.02,\n",
    "        metrics=[ConvergenceMetric.AVAILABILITY, ConvergenceMetric.COST],\n",
    "    ),\n",
    ")\n",
    "\n",
    "for metric, n in estimates.items():\n",
    "    print(f\"  {metric.value}: ~{n} runs needed for 95% CI with 5% relative error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Watch convergence happen in real-time\n",
    "#\n",
    "# This uses a progress callback to print status after every batch,\n",
    "# so you can see the estimated sample size shrink as variance stabilises.\n",
    "\n",
    "print(f\"{'Completed':>10} {'Est. Total':>11} {'Converged':>10}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "def on_progress(completed, estimated_total, converged):\n",
    "    print(f\"{completed:>10} {estimated_total:>11} {'  yes' if converged else '   no':>10}\")\n",
    "\n",
    "converged_example = run_monte_carlo_converged(\n",
    "    cluster_factory=lambda: create_cluster(5),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    max_time=days(365),\n",
    "    confidence_level=0.95,\n",
    "    relative_error=0.05,\n",
    "    metrics=[ConvergenceMetric.AVAILABILITY, ConvergenceMetric.COST],\n",
    "    stop_on_data_loss=True,\n",
    "    seed=123,\n",
    "    min_runs=30,\n",
    "    max_runs=2000,\n",
    "    batch_size=20,\n",
    "    progress_callback=on_progress,\n",
    ")\n",
    "\n",
    "print()\n",
    "print(f\"Finished in {converged_example.total_runs} runs \"\n",
    "      f\"(converged: {converged_example.converged})\")\n",
    "print()\n",
    "\n",
    "# Show per-metric detail\n",
    "for s in converged_example.metric_statuses:\n",
    "    ci_lo = s.current_mean - s.ci_half_width\n",
    "    ci_hi = s.current_mean + s.ci_half_width\n",
    "    print(f\"  {s.metric.value}:\")\n",
    "    print(f\"    mean = {s.current_mean:.4f}  \"\n",
    "          f\"95% CI = [{ci_lo:.4f}, {ci_hi:.4f}]  \"\n",
    "          f\"rel_error = {s.relative_error:.4f}\")\n",
    "\n",
    "# Compare: the fixed 100-run result from earlier\n",
    "print()\n",
    "print(f\"For comparison, the fixed 100-run result had availability \"\n",
    "      f\"std = {results_with_replacement.availability_std()*100:.2f}% \"\n",
    "      f\"across only {len(results_with_replacement.availability_samples)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decimal-place accuracy with absolute error\n",
    "\n",
    "The examples above use `relative_error`, which bounds the CI half-width as a\n",
    "fraction of the mean (e.g., 5% of the mean). But if you want availability\n",
    "accurate to a specific number of **decimal places**, use `absolute_error` instead.\n",
    "\n",
    "| Desired accuracy | `absolute_error` value | Meaning |\n",
    "|---|---|---|\n",
    "| 1 decimal place on the fraction | `0.1` | mean ± 0.1 (e.g., 0.4 ± 0.1) |\n",
    "| 2 decimal places on the fraction | `0.01` | mean ± 0.01 (e.g., 0.45 ± 0.01) |\n",
    "| 1 decimal place on the percentage | `0.001` | mean ± 0.1% (e.g., 45.7% ± 0.1%) |\n",
    "| 2 decimal places on the percentage | `0.0001` | mean ± 0.01% (e.g., 45.74% ± 0.01%) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get availability accurate to 2 decimal places on the fraction (±0.01)\n",
    "# i.e. if the true mean is 0.4574, we want our estimate in [0.4474, 0.4674]\n",
    "\n",
    "result_2dp = run_monte_carlo_converged(\n",
    "    cluster_factory=lambda: create_cluster(5),\n",
    "    strategy_factory=make_replacement_strategy,\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    max_time=days(365),\n",
    "    confidence_level=0.95,\n",
    "    absolute_error=0.01,  # ±0.01 on the availability fraction\n",
    "    metrics=[ConvergenceMetric.AVAILABILITY],\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    "    min_runs=30,\n",
    "    max_runs=10_000,\n",
    "    batch_size=50,\n",
    ")\n",
    "\n",
    "status = result_2dp.metric_statuses[0]\n",
    "mean = status.current_mean\n",
    "hw = status.ci_half_width\n",
    "\n",
    "print(f\"Runs needed: {result_2dp.total_runs}\")\n",
    "print(f\"Availability: {mean:.4f}  95% CI: [{mean - hw:.4f}, {mean + hw:.4f}]\")\n",
    "print(f\"CI half-width: ±{hw:.4f}  (target: ±0.0100)\")\n",
    "print(f\"Converged: {result_2dp.converged}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results\n",
    "\n",
    "### 5.1 Availability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF histogram of availability\n",
    "avail_samples = [a * 100 for a in results_with_replacement.availability_samples]\n",
    "fig = make_pdf_histogram(\n",
    "    samples=avail_samples,\n",
    "    title=\"Availability Distribution (with Replacement Strategy)\",\n",
    "    x_label=\"Availability (%)\",\n",
    "    bins=30,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare availability between strategies\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=[results_no_op, results_with_replacement],\n",
    "    labels=[\"No Intervention\", \"With Replacement\"],\n",
    "    title=\"Availability Comparison: No Intervention vs Replacement Strategy\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Time to Data Loss Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDF of time to actual data loss (NoOp strategy)\n",
    "loss_times_days = [t / 86400 for t in results_no_op.time_to_actual_loss_samples_filtered()]\n",
    "\n",
    "if loss_times_days:\n",
    "    fig = make_cdf_plot(\n",
    "        samples=loss_times_days,\n",
    "        title=\"Time to Data Loss CDF (No Intervention)\",\n",
    "        x_label=\"Days\",\n",
    "        show_percentiles=[50, 90, 99],\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data loss events occurred in the simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF histogram of time to data loss\n",
    "if loss_times_days:\n",
    "    fig = make_pdf_histogram(\n",
    "        samples=loss_times_days,\n",
    "        title=\"Time to Data Loss PDF (No Intervention)\",\n",
    "        x_label=\"Days\",\n",
    "        bins=30,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parameter Sensitivity Analysis\n",
    "\n",
    "Let's see how the number of nodes affects availability and time to data loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 3, 5, and 7 node clusters\n",
    "results_by_size = {}\n",
    "\n",
    "for num_nodes in [3, 5, 7]:\n",
    "    results = run_monte_carlo(\n",
    "        cluster_factory=lambda n=num_nodes: create_cluster(n),\n",
    "        strategy_factory=make_replacement_strategy,\n",
    "        protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "        num_simulations=50,\n",
    "        max_time=days(365),\n",
    "        stop_on_data_loss=True,\n",
    "        seed=42,\n",
    "    )\n",
    "    results_by_size[num_nodes] = results\n",
    "    print(f\"\\n{num_nodes}-node cluster:\")\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare availability across cluster sizes\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=list(results_by_size.values()),\n",
    "    labels=[f\"{n} nodes\" for n in results_by_size.keys()],\n",
    "    title=\"Availability by Cluster Size\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare time to data loss across cluster sizes\n",
    "fig = make_time_to_loss_comparison(\n",
    "    results_list=list(results_by_size.values()),\n",
    "    labels=[f\"{n} nodes\" for n in results_by_size.keys()],\n",
    "    title=\"Time to Data Loss by Cluster Size\",\n",
    "    actual=True,\n",
    "    time_unit=\"days\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Failure Scenarios\n",
    "\n",
    "Let's simulate a scenario with unreliable nodes (higher failure rates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unreliable_node_config(region: str = \"us-east\") -> NodeConfig:\n",
    "    \"\"\"Node with higher failure rates.\"\"\"\n",
    "    return NodeConfig(\n",
    "        region=region,\n",
    "        cost_per_hour=0.30,  # Cheaper but less reliable\n",
    "        # Transient failures: ~1 per day\n",
    "        failure_dist=Exponential(rate=1 / days(1)),\n",
    "        # Recovery time: 10-30 minutes (slower recovery)\n",
    "        recovery_dist=Uniform(low=minutes(10), high=minutes(30)),\n",
    "        # Permanent data loss: ~1 per 6 months\n",
    "        data_loss_dist=Exponential(rate=1 / days(180)),\n",
    "        log_replay_rate_dist=Constant(2.0),  # Slower log replay\n",
    "        snapshot_download_time_dist=Constant(minutes(10)),  # Slower snapshot download\n",
    "        spawn_dist=Uniform(low=minutes(15), high=minutes(30)),\n",
    "    )\n",
    "\n",
    "def create_unreliable_cluster(num_nodes: int = 5) -> ClusterState:\n",
    "    nodes = {}\n",
    "    for i in range(num_nodes):\n",
    "        config = make_unreliable_node_config()\n",
    "        nodes[f\"node{i}\"] = NodeState(\n",
    "            node_id=f\"node{i}\",\n",
    "            config=config,\n",
    "        )\n",
    "    return ClusterState(\n",
    "        nodes=nodes,\n",
    "        network=NetworkState(),\n",
    "        target_cluster_size=num_nodes,\n",
    "    )\n",
    "\n",
    "# Run simulation with unreliable nodes\n",
    "results_unreliable = run_monte_carlo(\n",
    "    cluster_factory=lambda: create_unreliable_cluster(5),\n",
    "    strategy_factory=lambda: SimpleReplacementStrategy(\n",
    "        default_node_config=make_unreliable_node_config(),\n",
    "    ),\n",
    "    protocol=LeaderlessUpToDateQuorumProtocol(),\n",
    "    num_simulations=100,\n",
    "    max_time=days(365),\n",
    "    stop_on_data_loss=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"Unreliable 5-node cluster:\")\n",
    "print(results_unreliable.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare reliable vs unreliable clusters\n",
    "fig = make_availability_boxplot(\n",
    "    results_list=[results_by_size[5], results_unreliable],\n",
    "    labels=[\"Reliable 5-node\", \"Unreliable 5-node\"],\n",
    "    title=\"Reliable vs Unreliable Nodes\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This simulator allows you to:\n",
    "\n",
    "1. **Model RSM deployments** with realistic node configurations\n",
    "2. **Define failure distributions** (exponential, Weibull, uniform, etc.)\n",
    "3. **Implement custom strategies** for handling failures\n",
    "4. **Run Monte Carlo simulations** to get statistical results\n",
    "5. **Visualize results** with PDFs, CDFs, and comparison plots\n",
    "\n",
    "Key metrics computed:\n",
    "- **Availability**: Fraction of time the system can accept commits\n",
    "- **Time to potential data loss**: When quorum is first lost\n",
    "- **Time to actual data loss**: When all up-to-date nodes fail\n",
    "- **Total cost**: Accumulated infrastructure costs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
