{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aade2f45-5101-47f8-ae2f-0027c003ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, astuple\n",
    "from typing import Dict, Tuple, Union, Optional\n",
    "from numbers import Number\n",
    "import wolframclient\n",
    "from wolframclient.evaluation import WolframLanguageSession\n",
    "from wolframclient.language import wl, wlexpr\n",
    "from wolframclient.serializers import export\n",
    "from fractions import Fraction\n",
    "from graphviz import Digraph\n",
    "import math\n",
    "import sympy as sym\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b3e8e-e592-4fe9-ae4b-6923dfdd99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set up wolfram session\n",
    "\n",
    "Get wolfram kernel path: https://reference.wolfram.com/language/WolframClientForPython/docpages/basic_usages.html\n",
    "Get wolfram license: https://software.berkeley.edu/mathematica\n",
    "\"\"\"\n",
    "\n",
    "wolfram_kernel_path_macos = \"/Applications/Wolfram.app/Contents/MacOS/WolframKernel\"\n",
    "wolfram_kernel_path_linux = \"/usr/local/Wolfram/Desktop/11.3/Executables/WolframKernel\"\n",
    "wolfram_kernel_path_windows = (\n",
    "    \"C:\\\\Program Files\\\\Wolfram Research\\\\Wolfram Desktop\\\\11.3\\\\WolframKernel.exe\"\n",
    ")\n",
    "\n",
    "\"\"\"Define your own desired wolfram_kernel_path\"\"\"\n",
    "my_wolfram_kernel_path = wolfram_kernel_path_macos\n",
    "\n",
    "# If you get an error, you may need to install wolframclient using pip and install wolfram language on your computer\n",
    "test_wolfram_session = WolframLanguageSession(wolfram_kernel_path_macos)\n",
    "test_wolfram_session.terminate()\n",
    "\n",
    "\n",
    "def wolfram_evals(\n",
    "    wolfram_expression: list[wolframclient.language.expression.WLInputExpression],\n",
    "    kernel_path: str = my_wolfram_kernel_path,\n",
    ") -> list[wolframclient.language.expression.WLFunction]:\n",
    "    \"\"\"\n",
    "    Evaluate a list of wolfram expressions in series with the same kernel and then close\n",
    "    Return each result in a list following the input order\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    with WolframLanguageSession(kernel_path) as session:\n",
    "        for expression in wolfram_expression:\n",
    "            results.append(session.evaluate(wolfram_expression))\n",
    "    return results\n",
    "\n",
    "\n",
    "def wolfram_eval(\n",
    "    wolfram_expression: wolframclient.language.expression.WLInputExpression,\n",
    "    kernel_path: str = my_wolfram_kernel_path,\n",
    ") -> wolframclient.language.expression.WLFunction:\n",
    "    \"\"\"\n",
    "    Evaluate a single wolfram expression and close\n",
    "    \"\"\"\n",
    "    with WolframLanguageSession(kernel_path) as session:\n",
    "        result = session.evaluate(wolfram_expression)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7bf73a-798b-433c-9d5f-a414443c348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossless_numerics = Union[Fraction, sym.Symbol, sym.Rational]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StateTransition:\n",
    "    \"\"\"\n",
    "    no self transition allowed (does not effect modeling theoretically due to exponential distribution memorylessness)\n",
    "    \"\"\"\n",
    "\n",
    "    state_name: str\n",
    "    transition_rates: list[Tuple[str, lossless_numerics]]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ContinuousMarkovModel:\n",
    "    initial_state_dist: dict[str, lossless_numerics]\n",
    "    state_transitions: list[StateTransition]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FailureParameters:\n",
    "    \"\"\"\n",
    "    Global parameters useful for modeling a node's failure/recovery behavior\n",
    "    \"\"\"\n",
    "\n",
    "    failure_rps: lossless_numerics\n",
    "    recovery_rps: lossless_numerics\n",
    "    human_recovery_rps: lossless_numerics\n",
    "    update_rps: lossless_numerics\n",
    "    outdate_rps: lossless_numerics\n",
    "\n",
    "\n",
    "def get_graphviz(\n",
    "    markov_model: ContinuousMarkovModel,\n",
    "    *,\n",
    "    simple_graph: bool = False,\n",
    "    show_weights: bool = False,\n",
    "    node_to_group: Optional[dict[str:str]] = None,\n",
    "    hide_edges_to_nodes: Optional[set[str]] = None,\n",
    "    source_node: Optional[str] = None,\n",
    ") -> Digraph:\n",
    "    if node_to_group is None:\n",
    "        node_to_group = {}\n",
    "    if hide_edges_to_nodes is None:\n",
    "        hide_edges_to_nodes = set()\n",
    "\n",
    "    dot = Digraph(strict=\"true\")\n",
    "    dot.attr(rankdir=\"LR\")\n",
    "    dot.attr(newrank=\"true\")\n",
    "    dot.attr(concentrate=\"true\")\n",
    "    node_to_id = {}\n",
    "    for x in markov_model.state_transitions:\n",
    "        if x.state_name not in node_to_id:\n",
    "            node_to_id[x.state_name] = str(len(node_to_id))\n",
    "        dot.node(\n",
    "            node_to_id[x.state_name],\n",
    "            label=x.state_name,\n",
    "            group=node_to_group.get(x.state_name, None),\n",
    "        )\n",
    "\n",
    "    for state_transition in markov_model.state_transitions:\n",
    "        starting_node = state_transition.state_name\n",
    "        for transition in state_transition.transition_rates:\n",
    "            ending_node, rate = transition\n",
    "            if ending_node in hide_edges_to_nodes:\n",
    "                continue\n",
    "            if show_weights:\n",
    "                if isinstance(rate, Number):\n",
    "                    dot.edge(\n",
    "                        node_to_id[starting_node],\n",
    "                        node_to_id[ending_node],\n",
    "                        label=\"{0:.4g}\".format(float(rate)),\n",
    "                    )\n",
    "                else:\n",
    "                    dot.edge(\n",
    "                        node_to_id[starting_node], node_to_id[ending_node], str(rate)\n",
    "                    )\n",
    "            else:\n",
    "                dot.edge(node_to_id[starting_node], node_to_id[ending_node])\n",
    "\n",
    "    if simple_graph:\n",
    "        return dot\n",
    "\n",
    "    source_group_id = node_to_group.get(source_node)\n",
    "    for group_id in set(node_to_group.values()):\n",
    "        nodes_in_group = [k for k, v in node_to_group.items() if v == group_id]\n",
    "        with dot.subgraph(name=f\"cluster_{group_id}\") as sub:\n",
    "            sub.attr(pencolor=\"gray\")\n",
    "            sub.attr(style=\"dashed\")\n",
    "            for node in nodes_in_group:\n",
    "                sub.node(node_to_id[node])\n",
    "            if group_id == source_group_id:\n",
    "                sub.attr(rank=\"min\")\n",
    "            else:\n",
    "                sub.attr(rank=\"same\")\n",
    "\n",
    "    # Hack to make Failed appear rightmost\n",
    "    if \"Failed\" in node_to_id:\n",
    "        with dot.subgraph() as sub:\n",
    "            sub.attr(rank=\"sink\")\n",
    "            sub.node(node_to_id[\"Failed\"])\n",
    "\n",
    "    return dot\n",
    "\n",
    "\n",
    "def working_and_backup_grouping(markov_model: ContinuousMarkovModel) -> dict[str, str]:\n",
    "    working_and_backup_grouping = {}\n",
    "    for state_transition in markov_model.state_transitions:\n",
    "        cur_state_name = state_transition.state_name\n",
    "        numbers = cur_state_name.split(\":\")\n",
    "        if any(not number.isnumeric() for number in numbers):\n",
    "            continue\n",
    "        num_backups = (\n",
    "            \"0\" if len(numbers) < 4 else str(int(numbers[2]) + int(numbers[3]))\n",
    "        )\n",
    "        num_working = \"0\"\n",
    "        for number in numbers[:2]:\n",
    "            num_working = str(int(num_working) + int(number))\n",
    "        working_and_backup_grouping[cur_state_name] = num_working + \"_\" + num_backups\n",
    "    return working_and_backup_grouping\n",
    "\n",
    "\n",
    "def get_state_to_id_dict(\n",
    "    markov_model: ContinuousMarkovModel,\n",
    ") -> Optional[dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Algorithm:\n",
    "    * state_transitions[i].cur_state_name becomes state i\n",
    "    * states in initial_state_dist are ignored\n",
    "    \"\"\"\n",
    "    state_name_to_id = {}\n",
    "    for i, state_transition in enumerate(markov_model.state_transitions):\n",
    "        if state_transition.state_name in state_name_to_id:\n",
    "            print(\n",
    "                f\"Error -- cannot generate transition matrix, found duplicate state [state_transition.state_name]\"\n",
    "            )\n",
    "            return\n",
    "        state_name_to_id[state_transition.state_name] = i\n",
    "    return state_name_to_id\n",
    "\n",
    "\n",
    "def get_wolfram_failed_id(cmm: ContinuousMarkovModel) -> int:\n",
    "    return get_state_to_id_dict(cmm)[\"Failed\"] + 1\n",
    "\n",
    "\n",
    "def get_initial_state_dist(\n",
    "    markov_model: ContinuousMarkovModel,\n",
    ") -> Optional[list[lossless_numerics]]:\n",
    "    state_name_to_id = get_state_to_id_dict(markov_model)\n",
    "    if state_name_to_id is None:\n",
    "        return\n",
    "    num_states = len(state_name_to_id)\n",
    "    output_vector = [0] * num_states\n",
    "    for state_name, probability in markov_model.initial_state_dist.items():\n",
    "        state_id = state_name_to_id[state_name]\n",
    "        output_vector[state_id] = probability\n",
    "    return output_vector\n",
    "\n",
    "\n",
    "def get_transition_matrix(markov_model: ContinuousMarkovModel) -> Optional[sym.Matrix]:\n",
    "    \"\"\"\n",
    "    Algorithm:\n",
    "    1. all_transition_rates[i].cur_state_name becomes state i\n",
    "    2. For output matrix Q,\n",
    "            if i != j: let Q[i][j] = be transition rate of i->j or zero if no rate specified\n",
    "            otw:       let Q[i][i] = be -(Q[i][0] + Q[i][1] +...+ Q[i][i-1] + Q[i][i+1] +...+Q[i][len(all_transition_rates])\n",
    "    *** 2b is required for wolfram logic\n",
    "    \"\"\"\n",
    "    state_name_to_id = get_state_to_id_dict(markov_model)\n",
    "    if state_name_to_id is None:\n",
    "        return None\n",
    "    num_states = len(state_name_to_id)\n",
    "    output_matrix = sym.zeros(num_states, num_states)\n",
    "    # Set transitions to be the rate per second\n",
    "    for state_transition in markov_model.state_transitions:\n",
    "        starting_state_name = state_transition.state_name\n",
    "        starting_state_id = state_name_to_id[starting_state_name]\n",
    "        for ending_state_name, transition_rate in state_transition.transition_rates:\n",
    "            ending_state_id = state_name_to_id[ending_state_name]\n",
    "            output_matrix[starting_state_id, ending_state_id] = transition_rate\n",
    "\n",
    "    # Set diagonal to be negative total transition\n",
    "    for i in range(output_matrix.shape[0]):\n",
    "        row = output_matrix.row(i)\n",
    "        output_matrix[i, i] = -np.sum(row)\n",
    "\n",
    "    return output_matrix\n",
    "\n",
    "\n",
    "def get_wolfram_markov_model(markov_model: ContinuousMarkovModel):\n",
    "    \"\"\"\n",
    "    Convert a markov model into a wolfram language object\n",
    "    \"\"\"\n",
    "    transition_matrix = wlexpr(\n",
    "        sym.printing.mathematica.mathematica_code(get_transition_matrix(markov_model))\n",
    "    )\n",
    "    initial_state_dist = wlexpr(\n",
    "        sym.printing.mathematica.mathematica_code(get_initial_state_dist(markov_model))\n",
    "    )\n",
    "    return wl.ContinuousMarkovProcess(initial_state_dist, transition_matrix)\n",
    "\n",
    "\n",
    "def convert_wolfram_number(n) -> float:\n",
    "    if type(n) == int:\n",
    "        return float(n)\n",
    "    if type(n) == wolframclient.language.expression.WLFunction:\n",
    "        return float(Fraction(n[0], n[1]))\n",
    "    print(f\"unexpected type {type(n)}\")\n",
    "    return\n",
    "\n",
    "\n",
    "def generate_fractions(start: Fraction, end: Fraction, num: int) -> list[Fraction]:\n",
    "    \"\"\"\n",
    "    Generates a list of equally spaced fractions within a range.\n",
    "\n",
    "    Args:\n",
    "      start: The starting value (inclusive) as a Fraction.\n",
    "      end: The ending value (inclusive) as a Fraction.\n",
    "      num: The number of fractions to generate.\n",
    "\n",
    "    Returns:\n",
    "      A list of Fractions.\n",
    "    \"\"\"\n",
    "    num = int(num)\n",
    "    if num <= 0:\n",
    "        return []\n",
    "    if num == 1:\n",
    "        return [start + end / 2]\n",
    "\n",
    "    step = (end - start) / (num - 1)\n",
    "    return [start + i * step for i in range(num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32aa2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_empty_transitions(markov_model: ContinuousMarkovModel):\n",
    "    states_with_transitions = set(\n",
    "        [x.state_name for x in markov_model.state_transitions]\n",
    "    )\n",
    "    states_in_total = (\n",
    "        [x.state_name for x in markov_model.state_transitions]\n",
    "        + [\n",
    "            transition_rate[0]\n",
    "            for state_transition in markov_model.state_transitions\n",
    "            for transition_rate in state_transition.transition_rates\n",
    "        ]\n",
    "        + list(markov_model.initial_state_dist.keys())\n",
    "    )\n",
    "    for state in states_in_total:\n",
    "        if state not in states_with_transitions:\n",
    "            markov_model.state_transitions.append(\n",
    "                StateTransition(state_name=state, transition_rates=[])\n",
    "            )\n",
    "\n",
    "\n",
    "def get_cmm(\n",
    "    num_nodes: int,\n",
    "    failure_params: FailureParameters,\n",
    "    *,\n",
    "    initial_state_dist: Optional[dict[str, lossless_numerics]] = None,\n",
    ") -> ContinuousMarkovModel:\n",
    "    if initial_state_dist is None:\n",
    "        initial_state_dist = {\"0f\": Fraction(1, 1)}\n",
    "    max_num_failures = int(math.ceil(num_nodes / 2)) - 1\n",
    "    state_transitions = [\n",
    "        StateTransition(  # 0f can only fail, no recovery\n",
    "            state_name=\"0f\",\n",
    "            transition_rates=[(\"1f\", num_nodes * failure_params.failure_rps)],\n",
    "        ),\n",
    "        StateTransition(  # Failed can only recover, not fail\n",
    "            state_name=\"Failed\",\n",
    "            transition_rates=[(\"0f\", failure_params.human_recovery_rps)],\n",
    "        ),\n",
    "        StateTransition(  # Failed - 1 transitions to Failed instead of '<num_failed>f'\n",
    "            state_name=f\"{max_num_failures}f\",\n",
    "            transition_rates=[\n",
    "                (f\"{max_num_failures - 1}f\", failure_params.recovery_rps),\n",
    "                (\"Failed\", (num_nodes - max_num_failures) * failure_params.failure_rps),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    for num_failures in range(1, max_num_failures):\n",
    "        cur_num_working_nodes = num_nodes - num_failures\n",
    "        state_transitions.append(\n",
    "            StateTransition(\n",
    "                state_name=f\"{num_failures}f\",\n",
    "                transition_rates=[\n",
    "                    (f\"{num_failures - 1}f\", failure_params.recovery_rps),\n",
    "                    (\n",
    "                        f\"{num_failures + 1}f\",\n",
    "                        cur_num_working_nodes * failure_params.failure_rps,\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "    return ContinuousMarkovModel(\n",
    "        initial_state_dist=initial_state_dist,\n",
    "        state_transitions=state_transitions,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dr_cmm(\n",
    "    num_nodes: int,\n",
    "    failure_params: FailureParameters,\n",
    "    *,\n",
    "    initial_state_dist: Optional[dict[str, lossless_numerics]] = None,\n",
    ") -> ContinuousMarkovModel:\n",
    "    if initial_state_dist is None:\n",
    "        initial_state_dist = {f\"{num_nodes}:0\": Fraction(1, 1)}\n",
    "    state_transitions = [\n",
    "        StateTransition(  # Failed can only recover, not fail\n",
    "            state_name=\"Failed\",\n",
    "            transition_rates=[(f\"{num_nodes}:0\", failure_params.human_recovery_rps)],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    unexplored_states = [f\"{num_nodes}:0\"]\n",
    "    discovered_states = set([\"Failed\", f\"{num_nodes}:0\"])\n",
    "    max_failures = int(math.ceil(num_nodes / 2)) - 1\n",
    "    min_updated_to_commit = num_nodes - max_failures\n",
    "\n",
    "    while len(unexplored_states):\n",
    "        cur_state = unexplored_states.pop()\n",
    "        num_up_to_date = int(cur_state.split(\":\")[0])\n",
    "        num_out_of_date = int(cur_state.split(\":\")[1])\n",
    "        nodes_working = num_out_of_date + num_up_to_date\n",
    "        transition_rates = []\n",
    "\n",
    "        is_full_updated = num_up_to_date == nodes_working\n",
    "        is_able_to_commit = num_up_to_date >= min_updated_to_commit\n",
    "        is_not_live = nodes_working < min_updated_to_commit\n",
    "        should_recover = nodes_working < num_nodes\n",
    "\n",
    "        if not is_full_updated:\n",
    "            transition_rates.append(\n",
    "                (f\"{num_up_to_date+1}:{num_out_of_date-1}\", failure_params.update_rps)\n",
    "            )\n",
    "        if should_recover:\n",
    "            if is_able_to_commit:\n",
    "                transition_rates.append(\n",
    "                    (\n",
    "                        f\"{num_up_to_date+1}:{num_out_of_date}\",\n",
    "                        failure_params.recovery_rps,\n",
    "                    )\n",
    "                )\n",
    "            elif is_not_live:\n",
    "                transition_rates.append(\n",
    "                    (f\"{num_nodes}:0\", failure_params.human_recovery_rps)\n",
    "                )\n",
    "        if num_up_to_date > min_updated_to_commit:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{min_updated_to_commit}:{nodes_working-min_updated_to_commit}\",\n",
    "                    failure_params.outdate_rps,\n",
    "                )\n",
    "            )\n",
    "        if num_up_to_date > 1:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date-1}:{num_out_of_date}\",\n",
    "                    num_up_to_date * failure_params.failure_rps,\n",
    "                )\n",
    "            )\n",
    "        if num_up_to_date == 1:\n",
    "            transition_rates.append(\n",
    "                (f\"Failed\", num_up_to_date * failure_params.failure_rps)\n",
    "            )\n",
    "        if num_out_of_date > 0:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date}:{num_out_of_date-1}\",\n",
    "                    num_out_of_date * failure_params.failure_rps,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        new_states = [x[0] for x in transition_rates if x[0] not in discovered_states]\n",
    "        for state in new_states:\n",
    "            discovered_states.add(state)\n",
    "        unexplored_states.extend(new_states)\n",
    "\n",
    "        state_transitions.append(\n",
    "            StateTransition(\n",
    "                state_name=f\"{num_up_to_date}:{num_out_of_date}\",\n",
    "                transition_rates=transition_rates,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    cmm = ContinuousMarkovModel(\n",
    "        initial_state_dist=initial_state_dist,\n",
    "        state_transitions=state_transitions,\n",
    "    )\n",
    "    fill_empty_transitions(cmm)\n",
    "    return cmm\n",
    "\n",
    "\n",
    "def get_dr_good_bad_cmm(\n",
    "    num_reliable_nodes: int,\n",
    "    num_unreliable_nodes: int,\n",
    "    reliable_parameters: FailureParameters,\n",
    "    unreliable_parameters: FailureParameters,\n",
    "    *,\n",
    "    initial_state_dist: Optional[dict[str, lossless_numerics]] = None,\n",
    "):\n",
    "    starting_state = f\"{num_reliable_nodes}:0:{num_unreliable_nodes}:0\"\n",
    "    if initial_state_dist is None:\n",
    "        initial_state_dist = {starting_state: Fraction(1, 1)}\n",
    "    overall_human_recovery_rate = max(\n",
    "        reliable_parameters.human_recovery_rps, unreliable_parameters.human_recovery_rps\n",
    "    )\n",
    "    state_transitions = [\n",
    "        StateTransition(  # Failed can only recover, not fail\n",
    "            state_name=\"Failed\",\n",
    "            transition_rates=[(starting_state, overall_human_recovery_rate)],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    num_nodes = num_reliable_nodes + num_unreliable_nodes\n",
    "    unexplored_states = [starting_state]\n",
    "    discovered_states = set([\"Failed\", starting_state])\n",
    "    max_failures = int(math.ceil(num_nodes / 2)) - 1\n",
    "    min_updated_to_commit = num_nodes - max_failures\n",
    "\n",
    "    while len(unexplored_states):\n",
    "        cur_state = unexplored_states.pop()\n",
    "        (\n",
    "            num_reliable_up_to_date,\n",
    "            num_reliable_out_of_date,\n",
    "            num_unreliable_up_to_date,\n",
    "            num_unreliable_out_of_date,\n",
    "        ) = [int(x) for x in cur_state.split(\":\")]\n",
    "\n",
    "        num_up_to_date = num_reliable_up_to_date + num_unreliable_up_to_date\n",
    "        num_out_of_date = num_reliable_out_of_date + num_unreliable_out_of_date\n",
    "        reliable_nodes_working = num_reliable_out_of_date + num_reliable_up_to_date\n",
    "        unreliable_nodes_working = (\n",
    "            num_unreliable_out_of_date + num_unreliable_up_to_date\n",
    "        )\n",
    "        nodes_working = reliable_nodes_working + unreliable_nodes_working\n",
    "        transition_rates = []\n",
    "\n",
    "        is_reliable_full_updated = num_reliable_up_to_date == reliable_nodes_working\n",
    "        is_unreliable_full_updated = (\n",
    "            num_unreliable_up_to_date == unreliable_nodes_working\n",
    "        )\n",
    "        min_reliable_updated_to_commit = (\n",
    "            min_updated_to_commit - num_unreliable_up_to_date\n",
    "        )\n",
    "        min_unreliable_updated_to_commit = (\n",
    "            min_updated_to_commit - num_reliable_up_to_date\n",
    "        )\n",
    "\n",
    "        is_able_to_commit = num_up_to_date >= min_updated_to_commit\n",
    "        is_not_live = nodes_working < min_updated_to_commit\n",
    "\n",
    "        should_reliable_recover = reliable_nodes_working < num_reliable_nodes\n",
    "        should_unreliable_recover = unreliable_nodes_working < num_unreliable_nodes\n",
    "\n",
    "        num_ways_to_recover = int(should_reliable_recover and is_able_to_commit) + int(\n",
    "            should_unreliable_recover and is_able_to_commit\n",
    "        )\n",
    "        # Reliable Recovery\n",
    "        if should_reliable_recover and is_able_to_commit:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_reliable_up_to_date + 1}:{num_reliable_out_of_date}:{num_unreliable_up_to_date}:{num_unreliable_out_of_date}\",\n",
    "                    reliable_parameters.recovery_rps / num_ways_to_recover,\n",
    "                )\n",
    "            )\n",
    "        # Unreliable Recovery\n",
    "        if should_unreliable_recover and is_able_to_commit:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_reliable_up_to_date}:{num_reliable_out_of_date}:{num_unreliable_up_to_date + 1}:{num_unreliable_out_of_date}\",\n",
    "                    unreliable_parameters.recovery_rps / num_ways_to_recover,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Human Recovery\n",
    "        if (should_reliable_recover or should_unreliable_recover) and is_not_live:\n",
    "            transition_rates.append((starting_state, overall_human_recovery_rate))\n",
    "\n",
    "        # Reliable Update/Outdate\n",
    "        if not is_reliable_full_updated:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_reliable_up_to_date + 1}:{num_reliable_out_of_date - 1}:{num_unreliable_up_to_date}:{num_unreliable_out_of_date}\",\n",
    "                    reliable_parameters.update_rps,\n",
    "                )\n",
    "            )\n",
    "        if (\n",
    "            is_able_to_commit\n",
    "            and num_reliable_up_to_date > min_reliable_updated_to_commit\n",
    "        ):  # pessimistic -- we could also outdate to fewer to no reliable nodes at different rates\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{min_reliable_updated_to_commit}:{reliable_nodes_working-min_reliable_updated_to_commit}:{num_unreliable_up_to_date}:{num_unreliable_out_of_date}\",\n",
    "                    reliable_parameters.outdate_rps,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Unreliable Update/Outdate\n",
    "        if not is_unreliable_full_updated:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_reliable_up_to_date}:{num_reliable_out_of_date}:{num_unreliable_up_to_date + 1}:{num_unreliable_out_of_date - 1}\",\n",
    "                    unreliable_parameters.update_rps,\n",
    "                )\n",
    "            )\n",
    "        if (\n",
    "            is_able_to_commit\n",
    "            and num_unreliable_up_to_date > min_unreliable_updated_to_commit\n",
    "        ):  # pessimistic -- we could also outdate to fewer to no unreliable nodes at different rates\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_reliable_up_to_date}:{num_reliable_out_of_date}:{min_unreliable_updated_to_commit}:{unreliable_nodes_working - min_unreliable_updated_to_commit}\",\n",
    "                    unreliable_parameters.outdate_rps,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        is_reliable_last_hope = (\n",
    "            num_reliable_up_to_date == 1 and num_unreliable_up_to_date == 0\n",
    "        )\n",
    "        is_unreliable_last_hope = (\n",
    "            num_reliable_up_to_date == 0 and num_unreliable_up_to_date == 1\n",
    "        )\n",
    "\n",
    "        # Reliable Failure\n",
    "        if is_reliable_last_hope:\n",
    "            transition_rates.append((f\"Failed\", reliable_parameters.failure_rps))\n",
    "        elif num_reliable_up_to_date > 0:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_reliable_up_to_date - 1}:{num_reliable_out_of_date}:{num_unreliable_up_to_date}:{num_unreliable_out_of_date}\",\n",
    "                    num_reliable_up_to_date * reliable_parameters.failure_rps,\n",
    "                )\n",
    "            )\n",
    "        if num_reliable_out_of_date > 0:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_reliable_up_to_date}:{num_reliable_out_of_date - 1}:{num_unreliable_up_to_date}:{num_unreliable_out_of_date}\",\n",
    "                    num_reliable_out_of_date * reliable_parameters.failure_rps,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Unreliable Failure\n",
    "        if is_unreliable_last_hope:\n",
    "            transition_rates.append((f\"Failed\", unreliable_parameters.failure_rps))\n",
    "        elif num_unreliable_up_to_date > 0:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_reliable_up_to_date}:{num_reliable_out_of_date}:{num_unreliable_up_to_date - 1}:{num_unreliable_out_of_date}\",\n",
    "                    num_unreliable_up_to_date * unreliable_parameters.failure_rps,\n",
    "                )\n",
    "            )\n",
    "        if num_unreliable_out_of_date > 0:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_reliable_up_to_date}:{num_reliable_out_of_date}:{num_unreliable_up_to_date}:{num_unreliable_out_of_date - 1}\",\n",
    "                    num_unreliable_out_of_date * unreliable_parameters.failure_rps,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        new_states = [x[0] for x in transition_rates if x[0] not in discovered_states]\n",
    "        for state in new_states:\n",
    "            discovered_states.add(state)\n",
    "        unexplored_states.extend(new_states)\n",
    "\n",
    "        state_transitions.append(\n",
    "            StateTransition(\n",
    "                state_name=cur_state,\n",
    "                transition_rates=transition_rates,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    cmm = ContinuousMarkovModel(\n",
    "        initial_state_dist=initial_state_dist,\n",
    "        state_transitions=state_transitions,\n",
    "    )\n",
    "    fill_empty_transitions(cmm)\n",
    "    return cmm\n",
    "\n",
    "\n",
    "def get_dr_backup_cmm(\n",
    "    num_nodes: int,\n",
    "    num_backups: int,\n",
    "    replica_parameters: FailureParameters,\n",
    "    backup_parameters: FailureParameters,\n",
    "    *,\n",
    "    initial_state_dist: Optional[dict[str, lossless_numerics]] = None,\n",
    "):\n",
    "    # num_nodes many nodes are up to date, and num_backups many nodes are up to date\n",
    "    full_functional_state_name = f\"{num_nodes}:0:{num_backups}:0\"\n",
    "    if initial_state_dist is None:\n",
    "        initial_state_dist = {full_functional_state_name: Fraction(1, 1)}\n",
    "    state_transitions = [\n",
    "        StateTransition(  # Failed can only recover, not fail\n",
    "            state_name=\"Failed\",\n",
    "            transition_rates=[\n",
    "                (full_functional_state_name, replica_parameters.human_recovery_rps)\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    unexplored_states = [full_functional_state_name]\n",
    "    discovered_states = set([\"Failed\", full_functional_state_name])\n",
    "    max_failures = int(math.ceil(num_nodes / 2)) - 1\n",
    "    min_updated_to_commit = num_nodes - max_failures\n",
    "\n",
    "    while len(unexplored_states):\n",
    "        cur_state = unexplored_states.pop()\n",
    "        (\n",
    "            num_up_to_date,\n",
    "            num_out_of_date,\n",
    "            num_backups_up_to_date,\n",
    "            num_backups_out_of_date,\n",
    "        ) = [int(x) for x in cur_state.split(\":\")]\n",
    "        nodes_working = num_out_of_date + num_up_to_date\n",
    "        backups_working = num_backups_up_to_date + num_backups_out_of_date\n",
    "        transition_rates = []\n",
    "\n",
    "        is_rsm_updated = num_up_to_date == nodes_working\n",
    "        is_able_to_commit = num_up_to_date >= min_updated_to_commit\n",
    "        is_backup_updated = num_backups_up_to_date == backups_working\n",
    "        is_not_live = nodes_working < min_updated_to_commit\n",
    "        should_rsm_recover = nodes_working < num_nodes\n",
    "        should_backups_recover = backups_working < num_backups\n",
    "\n",
    "        num_ways_to_recover = int(should_rsm_recover and is_able_to_commit) + int(\n",
    "            should_backups_recover\n",
    "        )\n",
    "        # RSM recovery\n",
    "        if should_rsm_recover:\n",
    "            if is_able_to_commit:  # commit to recovery automatically\n",
    "                transition_rates.append(\n",
    "                    (\n",
    "                        f\"{num_up_to_date+1}:{num_out_of_date}:{num_backups_up_to_date}:{num_backups_out_of_date}\",\n",
    "                        replica_parameters.recovery_rps / num_ways_to_recover,\n",
    "                    )\n",
    "                )\n",
    "            elif is_not_live:  # human recovery if too many nodes failed to commit\n",
    "                transition_rates.append(\n",
    "                    (\n",
    "                        f\"{num_nodes}:0:{num_backups_up_to_date}:{num_backups_out_of_date}\",\n",
    "                        replica_parameters.human_recovery_rps,\n",
    "                    )\n",
    "                )\n",
    "        # backup recovery\n",
    "        if should_backups_recover:  # backups can always recover\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date}:{num_out_of_date}:{num_backups_up_to_date+1}:{num_backups_out_of_date}\",\n",
    "                    backup_parameters.recovery_rps / num_ways_to_recover,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # RSM update/outdate\n",
    "        if not is_rsm_updated:  # If we need to update the RSM we will\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date+1}:{num_out_of_date-1}:{num_backups_up_to_date}:{num_backups_out_of_date}\",\n",
    "                    replica_parameters.update_rps,\n",
    "                )\n",
    "            )\n",
    "        if (\n",
    "            num_up_to_date > min_updated_to_commit\n",
    "        ):  # If we can commit, we might throw nodes out of date\n",
    "            # optional: for i in range(min_updated_to_commit, num_up_to_date+1): add transition to outdate i nodes (\\times num_backups)\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{min_updated_to_commit}:{nodes_working-min_updated_to_commit}:{num_backups_up_to_date}:{num_backups_out_of_date}\",\n",
    "                    replica_parameters.outdate_rps,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Backup update/outdate\n",
    "        if not is_backup_updated:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date}:{num_out_of_date}:{num_backups_up_to_date+1}:{num_backups_out_of_date-1}\",\n",
    "                    backup_parameters.update_rps,\n",
    "                )\n",
    "            )\n",
    "        if is_able_to_commit and num_backups_up_to_date > 0:\n",
    "            # optional: for i in range(0, backups_working+1): add transition to outdate i backups (\\times num_up_to_date)\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date}:{num_out_of_date}:{0}:{backups_working}\",\n",
    "                    backup_parameters.outdate_rps,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        is_rsm_last_hope = num_up_to_date == 1 and num_backups_up_to_date == 0\n",
    "        is_backup_last_hope = num_up_to_date == 0 and num_backups_up_to_date == 1\n",
    "\n",
    "        # RSM failure\n",
    "        if is_rsm_last_hope:\n",
    "            transition_rates.append(\n",
    "                (f\"Failed\", num_up_to_date * replica_parameters.failure_rps)\n",
    "            )\n",
    "        elif num_up_to_date > 0:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date-1}:{num_out_of_date}:{num_backups_up_to_date}:{num_backups_out_of_date}\",\n",
    "                    num_up_to_date * replica_parameters.failure_rps,\n",
    "                )\n",
    "            )\n",
    "        if num_out_of_date > 0:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date}:{num_out_of_date-1}:{num_backups_up_to_date}:{num_backups_out_of_date}\",\n",
    "                    num_out_of_date * replica_parameters.failure_rps,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Backup failure\n",
    "        if is_backup_last_hope:\n",
    "            transition_rates.append(\n",
    "                (f\"Failed\", num_backups_up_to_date * backup_parameters.failure_rps)\n",
    "            )\n",
    "        elif num_backups_up_to_date > 0:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date}:{num_out_of_date}:{num_backups_up_to_date-1}:{num_backups_out_of_date}\",\n",
    "                    num_backups_up_to_date * backup_parameters.failure_rps,\n",
    "                )\n",
    "            )\n",
    "        if num_backups_out_of_date > 0:\n",
    "            transition_rates.append(\n",
    "                (\n",
    "                    f\"{num_up_to_date}:{num_out_of_date}:{num_backups_up_to_date}:{num_backups_out_of_date-1}\",\n",
    "                    num_backups_out_of_date * backup_parameters.failure_rps,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        new_states = [x[0] for x in transition_rates if x[0] not in discovered_states]\n",
    "        for state in new_states:\n",
    "            discovered_states.add(state)\n",
    "        unexplored_states.extend(new_states)\n",
    "\n",
    "        state_transitions.append(\n",
    "            StateTransition(\n",
    "                state_name=cur_state,\n",
    "                transition_rates=transition_rates,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    cmm = ContinuousMarkovModel(\n",
    "        initial_state_dist=initial_state_dist,\n",
    "        state_transitions=state_transitions,\n",
    "    )\n",
    "    fill_empty_transitions(cmm)\n",
    "    return cmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814f26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Line:\n",
    "    x_values: list[float]\n",
    "    y_values: list[float]\n",
    "    name: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Graph:\n",
    "    title: str\n",
    "    x_axis_name: str\n",
    "    y_axis_name: str\n",
    "    lines: list[Line]\n",
    "\n",
    "\n",
    "def make_fig(graph: Graph) -> go.Figure:\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for line in graph.lines:\n",
    "        x_values, y_values, name = astuple(line)\n",
    "        fig.add_trace(go.Scatter(x=x_values, y=y_values, mode=\"lines\", name=name))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=graph.title,\n",
    "        xaxis_title=graph.x_axis_name,\n",
    "        yaxis_title=graph.y_axis_name,\n",
    "        showlegend=True,\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(type=\"log\")\n",
    "    fig.update_yaxes(type=\"log\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c783f030-7d32-4c6c-bcbd-0145945ecdb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FailureParameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conservative_failure_params \u001b[38;5;241m=\u001b[39m \u001b[43mFailureParameters\u001b[49m(\n\u001b[1;32m      2\u001b[0m     failure_rps\u001b[38;5;241m=\u001b[39m Fraction(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m24\u001b[39m),\n\u001b[1;32m      3\u001b[0m     recovery_rps\u001b[38;5;241m=\u001b[39m Fraction(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m      4\u001b[0m     human_recovery_rps\u001b[38;5;241m=\u001b[39m Fraction(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m      5\u001b[0m     update_rps\u001b[38;5;241m=\u001b[39m Fraction((\u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m), \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m      6\u001b[0m     outdate_rps\u001b[38;5;241m=\u001b[39m Fraction((\u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m), \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m bad_failure_params \u001b[38;5;241m=\u001b[39m FailureParameters(\n\u001b[1;32m     10\u001b[0m     failure_rps\u001b[38;5;241m=\u001b[39m Fraction(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m24\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     11\u001b[0m     recovery_rps\u001b[38;5;241m=\u001b[39m Fraction(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     outdate_rps\u001b[38;5;241m=\u001b[39m Fraction((\u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m), \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m sym_failure_params_capital \u001b[38;5;241m=\u001b[39m FailureParameters(\n\u001b[1;32m     18\u001b[0m     failure_rps\u001b[38;5;241m=\u001b[39m sym\u001b[38;5;241m.\u001b[39mSymbol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     19\u001b[0m     recovery_rps\u001b[38;5;241m=\u001b[39m sym\u001b[38;5;241m.\u001b[39mSymbol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     outdate_rps\u001b[38;5;241m=\u001b[39m sym\u001b[38;5;241m.\u001b[39mSymbol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FailureParameters' is not defined"
     ]
    }
   ],
   "source": [
    "conservative_failure_params = FailureParameters(\n",
    "    failure_rps=Fraction(1, 50 * 24),\n",
    "    recovery_rps=Fraction(1, 5),\n",
    "    human_recovery_rps=Fraction(1, 5),\n",
    "    update_rps=Fraction((60 * 60 * 1000), 10),\n",
    "    outdate_rps=Fraction((60 * 60 * 1000), 10),\n",
    ")\n",
    "\n",
    "bad_failure_params = FailureParameters(\n",
    "    failure_rps=Fraction(1, 50 * 24) * 2,\n",
    "    recovery_rps=Fraction(1, 5),\n",
    "    human_recovery_rps=Fraction(1, 5),\n",
    "    update_rps=Fraction((60 * 60 * 1000), 10),\n",
    "    outdate_rps=Fraction((60 * 60 * 1000), 10),\n",
    ")\n",
    "\n",
    "sym_failure_params_capital = FailureParameters(\n",
    "    failure_rps=sym.Symbol(\"B\"),\n",
    "    recovery_rps=sym.Symbol(\"R\"),\n",
    "    human_recovery_rps=sym.Symbol(\"H\"),\n",
    "    update_rps=sym.Symbol(\"U\"),\n",
    "    outdate_rps=sym.Symbol(\"O\"),\n",
    ")\n",
    "\n",
    "sym_failure_params_lowercase = FailureParameters(\n",
    "    failure_rps=sym.Symbol(\"b\"),\n",
    "    recovery_rps=sym.Symbol(\"r\"),\n",
    "    human_recovery_rps=sym.Symbol(\"h\"),\n",
    "    update_rps=sym.Symbol(\"u\"),\n",
    "    outdate_rps=sym.Symbol(\"o\"),\n",
    ")\n",
    "\n",
    "\n",
    "cmm = get_dr_backup_cmm(3, 1, conservative_failure_params, conservative_failure_params)\n",
    "# cmm = get_dr_cmm(3, conservative_failure_params)\n",
    "# cmm = get_dr_good_bad_cmm(2, 1, conservative_failure_params, conservative_failure_params)\n",
    "\n",
    "\n",
    "wolfram_mm = get_wolfram_markov_model(cmm)\n",
    "\n",
    "\n",
    "# wolfram_mm = get_wolfram_markov_model(cmm)\n",
    "failed_wolfram_id = get_state_to_id_dict(cmm)[\"Failed\"] + 1\n",
    "\n",
    "dist = wl.Mean(wl.FirstPassageTimeDistribution(wolfram_mm, failed_wolfram_id))\n",
    "\n",
    "round(float((convert_wolfram_number(wolfram_eval(dist)) / 365 / 24)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa130ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.1.2 (20240928.0832)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"452pt\" height=\"168pt\"\n",
       " viewBox=\"0.00 0.00 451.90 167.82\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 163.82)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-163.82 447.9,-163.82 447.9,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_2_0</title>\n",
       "<polygon fill=\"none\" stroke=\"gray\" stroke-dasharray=\"5,2\" points=\"188,-20.21 188,-126.21 258,-126.21 258,-20.21 188,-20.21\"/>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_4_0</title>\n",
       "<polygon fill=\"none\" stroke=\"gray\" stroke-dasharray=\"5,2\" points=\"8,-20.21 8,-126.21 78,-126.21 78,-20.21 8,-20.21\"/>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_1_0</title>\n",
       "<polygon fill=\"none\" stroke=\"gray\" stroke-dasharray=\"5,2\" points=\"278,-24.21 278,-76.21 348,-76.21 348,-24.21 278,-24.21\"/>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster_3_0</title>\n",
       "<polygon fill=\"none\" stroke=\"gray\" stroke-dasharray=\"5,2\" points=\"98,-20.21 98,-126.21 168,-126.21 168,-20.21 98,-20.21\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"409.95\" cy=\"-100.21\" rx=\"33.95\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"409.95\" y=\"-95.16\" font-family=\"Times,serif\" font-size=\"14.00\">Failed</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"43\" cy=\"-46.21\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-41.16\" font-family=\"Times,serif\" font-size=\"14.00\">4:0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M384.37,-112.5C327.9,-138.8 186.93,-193.25 98,-130.21 76.1,-114.68 93.57,-95.08 78,-73.21 76.16,-70.62 74,-68.15 71.68,-65.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"74.35,-63.52 64.52,-59.57 69.74,-68.79 74.35,-63.52\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"133\" cy=\"-46.21\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-41.16\" font-family=\"Times,serif\" font-size=\"14.00\">3:0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.51,-52.33C77.02,-52.92 86.75,-53.09 96,-52.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"95.97,-56.36 105.8,-52.41 95.65,-49.37 95.97,-56.36\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"43\" cy=\"-100.21\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-95.16\" font-family=\"Times,serif\" font-size=\"14.00\">3:1</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.09,-60.97C62.22,-65.57 63.58,-70.17 63.18,-74.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"59.92,-73.49 59.6,-84.08 66.46,-76 59.92,-73.49\"/>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.31,-40.07C98.79,-39.49 89.05,-39.32 79.82,-39.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.85,-36.06 70.02,-40.01 80.18,-43.05 79.85,-36.06\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"223\" cy=\"-46.21\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"223\" y=\"-41.16\" font-family=\"Times,serif\" font-size=\"14.00\">2:0</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.4,-46.21C167.89,-46.21 176.18,-46.21 184.2,-46.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.1,-49.71 194.1,-46.21 184.1,-42.71 184.1,-49.71\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M205.79,-31.79C191.35,-20.24 168.89,-5.33 145.28,-1.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.79,2.2 135.51,-0.35 145.14,-4.77 145.79,2.2\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"313\" cy=\"-50.21\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"313\" y=\"-45.16\" font-family=\"Times,serif\" font-size=\"14.00\">1:0</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.4,-47.41C257.89,-47.75 266.18,-48.12 274.2,-48.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"273.96,-51.98 284.1,-48.94 274.27,-44.99 273.96,-51.98\"/>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;0 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>4&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M334.6,-61.06C346.42,-67.28 361.56,-75.25 375.09,-82.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"373.22,-85.35 383.7,-86.91 376.48,-79.15 373.22,-85.35\"/>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M132,-0.21C104.25,0.44 76.6,-17.92 59.9,-31.64\"/>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M295.01,-36.81C284.84,-29.5 271.34,-21 258,-16.21 209.49,1.23 192.09,-0.47 145.46,-0.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.54,3.21 135.51,-0.22 145.49,-3.79 145.54,3.21\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M26.94,-85.49C23.81,-80.9 22.43,-76.3 22.81,-71.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"26.07,-72.98 26.37,-62.39 19.53,-70.48 26.07,-72.98\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.53,-88.22C75.15,-81.09 90.11,-71.91 103.08,-63.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"104.54,-67.16 111.23,-58.95 100.88,-61.2 104.54,-67.16\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"133\" cy=\"-100.21\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-95.16\" font-family=\"Times,serif\" font-size=\"14.00\">2:1</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.4,-100.21C77.89,-100.21 86.18,-100.21 94.2,-100.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.1,-103.71 104.1,-100.21 94.1,-96.71 94.1,-103.71\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;2 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>6&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M133,-81.72C133,-79.73 133,-77.74 133,-75.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"136.5,-75.86 133,-65.86 129.5,-75.86 136.5,-75.86\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;3 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>6&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.53,-88.22C165.15,-81.09 180.11,-71.91 193.08,-63.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194.54,-67.16 201.23,-58.95 190.88,-61.2 194.54,-67.16\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"223\" cy=\"-100.21\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"223\" y=\"-95.16\" font-family=\"Times,serif\" font-size=\"14.00\">1:1</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.4,-100.21C167.89,-100.21 176.18,-100.21 184.2,-100.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.1,-103.71 194.1,-100.21 184.1,-96.71 184.1,-103.71\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;0 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>7&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.5,-100.21C280.11,-100.21 328.56,-100.21 364.1,-100.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364.1,-103.71 374.1,-100.21 364.1,-96.71 364.1,-103.71\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;1 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>7&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.61,-87.84C197.3,-83.71 191.93,-78.73 188,-73.21 172.43,-51.33 185.99,-36.14 168,-16.21 159.78,-7.1 154.3,-2.85 145.36,-1.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.76,2.33 135.51,-0.33 145.18,-4.65 145.76,2.33\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223,-81.72C223,-79.73 223,-77.74 223,-75.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.5,-75.86 223,-65.86 219.5,-75.86 226.5,-75.86\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.41,-88.61C255.52,-82.3 269.47,-74.37 281.81,-67.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"283.42,-70.47 290.38,-62.49 279.96,-64.39 283.42,-70.47\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x10896e240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmm = get_dr_cmm(4, conservative_failure_params)\n",
    "get_graphviz(cmm, node_to_group=working_and_backup_grouping(cmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa019651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also try to vary automatic recovery rate + other parameters 5 outputs\n",
    "# Try to get the 5d symbolic mttf\n",
    "# Try to generate graphs automatically +++ Good graph visualization\n",
    "# Try to get parameter sweep sliders for graphs\n",
    "failure_rates = generate_fractions(Fraction(1, 1000 * 24), Fraction(1, 50 * 24), 1000)\n",
    "x_axis = [float(x) * 24 * 365.25 for x in failure_rates]\n",
    "mttf_three_node = []\n",
    "mttf_five_node = []\n",
    "mttf_opt_three_node = []\n",
    "mttf_opt_1b_three_node = []\n",
    "\n",
    "for failure_rps in failure_rates:\n",
    "    params = FailureParameters(\n",
    "        failure_rps=failure_rps,\n",
    "        recovery_rps=Fraction(1, 5),\n",
    "        human_recovery_rps=Fraction(1, 5),\n",
    "        update_rps=Fraction((60 * 60 * 1000), 10),\n",
    "        outdate_rps=Fraction((60 * 60 * 1000), 10),\n",
    "    )\n",
    "    cmm3 = get_three_node_CMM(params)\n",
    "    cmm5 = get_five_node_CMM(params)\n",
    "    cmm3opt = get_optimistic_three_node_CMM(params)\n",
    "    cmm3opt1b = get_optimistic_naiive_backup_three_node_CMM(params)\n",
    "\n",
    "    cmm3_ans = wolfram_session.evaluate(\n",
    "        wl.Mean(\n",
    "            wl.FirstPassageTimeDistribution(\n",
    "                get_wolfram_markov_model(cmm3), get_state_to_id_dict(cmm3)[\"Failed\"] + 1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    cmm5_ans = wolfram_session.evaluate(\n",
    "        wl.Mean(\n",
    "            wl.FirstPassageTimeDistribution(\n",
    "                get_wolfram_markov_model(cmm5), get_state_to_id_dict(cmm5)[\"Failed\"] + 1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    cmm3opt_ans = wolfram_session.evaluate(\n",
    "        wl.Mean(\n",
    "            wl.FirstPassageTimeDistribution(\n",
    "                get_wolfram_markov_model(cmm3opt),\n",
    "                get_state_to_id_dict(cmm3opt)[\"Failed\"] + 1,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    cmm3opt_1b_ans = wolfram_session.evaluate(\n",
    "        wl.Mean(\n",
    "            wl.FirstPassageTimeDistribution(\n",
    "                get_wolfram_markov_model(cmm3opt1b),\n",
    "                get_state_to_id_dict(cmm3opt1b)[\"Failed\"] + 1,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mttf_three_node.append(convert_wolfram_number(cmm3_ans) / 24 / 365.25)\n",
    "    mttf_five_node.append(convert_wolfram_number(cmm5_ans) / 24 / 365.25)\n",
    "    mttf_opt_three_node.append(convert_wolfram_number(cmm3opt_ans) / 24 / 365.25)\n",
    "    mttf_opt_1b_three_node.append(convert_wolfram_number(cmm3opt_1b_ans) / 24 / 365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also try to vary automatic recovery rate + other parameters 5 outputs\n",
    "# Try to get the 5d symbolic mttf\n",
    "# Try to generate graphs automatically +++ Good graph visualization\n",
    "# Try to get parameter sweep sliders for graphs\n",
    "failure_rates = generate_fractions(Fraction(1, 1000 * 24), Fraction(1, 50 * 24), 20)\n",
    "x_axis = [float(x) * 24 * 365.25 for x in failure_rates]\n",
    "\n",
    "mttf_three_node = []\n",
    "mttf_four_node = []\n",
    "mttf_five_node = []\n",
    "mttf_six_node = []\n",
    "mttf_seven_node = []\n",
    "\n",
    "mttf_opt_four_node = []\n",
    "mttf_opt_five_node = []\n",
    "mttf_opt_six_node = []\n",
    "mttf_opt_seven_node = []\n",
    "\n",
    "mttf_three_one_backup = []\n",
    "mttf_three_two_backup = []\n",
    "mttf_three_three_backup = []\n",
    "\n",
    "mttf_four_one_backup = []\n",
    "mttf_four_two_backup = []\n",
    "mttf_four_three_backup = []\n",
    "\n",
    "mttf_five_one_backup = []\n",
    "mttf_five_two_backup = []\n",
    "mttf_five_three_backup = []\n",
    "\n",
    "mttf_six_one_backup = []\n",
    "mttf_six_two_backup = []\n",
    "mttf_six_three_backup = []\n",
    "\n",
    "backup_arrs = [\n",
    "    mttf_three_one_backup,\n",
    "    mttf_three_two_backup,\n",
    "    mttf_three_three_backup,\n",
    "    mttf_four_one_backup,\n",
    "    mttf_four_two_backup,\n",
    "    mttf_four_three_backup,\n",
    "    mttf_five_one_backup,\n",
    "    mttf_five_two_backup,\n",
    "    mttf_five_three_backup,\n",
    "    mttf_six_one_backup,\n",
    "    mttf_six_two_backup,\n",
    "    mttf_six_three_backup,\n",
    "]\n",
    "\n",
    "\n",
    "with WolframLanguageSession(my_wolfram_kernel_path) as wolfram_session:\n",
    "    for failure_rps in failure_rates:\n",
    "        params = FailureParameters(\n",
    "            failure_rps=failure_rps,\n",
    "            recovery_rps=Fraction(1, 5),\n",
    "            human_recovery_rps=Fraction(1, 5),\n",
    "            update_rps=Fraction((60 * 60 * 1000), 10),\n",
    "            outdate_rps=Fraction((60 * 60 * 1000), 10),\n",
    "        )\n",
    "        cmm3 = get_cmm(3, params)\n",
    "        cmm5 = get_cmm(5, params)\n",
    "        cmm4 = get_cmm(4, params)\n",
    "        cmm6 = get_cmm(6, params)\n",
    "        cmm7 = get_cmm(7, params)\n",
    "\n",
    "        cmm4opt = get_dr_cmm(4, params)\n",
    "        cmm5opt = get_dr_cmm(5, params)\n",
    "        cmm6opt = get_dr_cmm(6, params)\n",
    "        cmm7opt = get_dr_cmm(7, params)\n",
    "\n",
    "        cmm3_1b = get_dr_backup_cmm(3, 1, params, params)\n",
    "\n",
    "        cmm3_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm3),\n",
    "                    get_state_to_id_dict(cmm3)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm5_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm5),\n",
    "                    get_state_to_id_dict(cmm5)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm4_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm4),\n",
    "                    get_state_to_id_dict(cmm4)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm6_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm6),\n",
    "                    get_state_to_id_dict(cmm6)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm7_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm7),\n",
    "                    get_state_to_id_dict(cmm7)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        cmm4opt_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm4opt),\n",
    "                    get_state_to_id_dict(cmm4opt)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm5opt_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm5opt),\n",
    "                    get_state_to_id_dict(cmm5opt)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm6opt_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm6opt),\n",
    "                    get_state_to_id_dict(cmm6opt)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm7opt_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm7opt),\n",
    "                    get_state_to_id_dict(cmm7opt)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for num_reps in range(3, 7):\n",
    "            for num_backups in range(1, 4):\n",
    "                cmm = get_dr_backup_cmm(num_reps, num_backups, params, params)\n",
    "                cmm_ans = wolfram_session.evaluate(\n",
    "                    wl.Mean(\n",
    "                        wl.FirstPassageTimeDistribution(\n",
    "                            get_wolfram_markov_model(cmm),\n",
    "                            get_state_to_id_dict(cmm)[\"Failed\"] + 1,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                backup_arrs[(num_reps - 3) * 3 + num_backups - 1].append(\n",
    "                    convert_wolfram_number(cmm_ans) / 24 / 365.25\n",
    "                )\n",
    "\n",
    "        cmm3_1b_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm3_1b),\n",
    "                    get_state_to_id_dict(cmm3_1b)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        mttf_three_node.append(convert_wolfram_number(cmm3_ans) / 24 / 365.25)\n",
    "        mttf_five_node.append(convert_wolfram_number(cmm5_ans) / 24 / 365.25)\n",
    "        mttf_four_node.append(convert_wolfram_number(cmm4_ans) / 24 / 365.25)\n",
    "        mttf_six_node.append(convert_wolfram_number(cmm6_ans) / 24 / 365.25)\n",
    "        mttf_seven_node.append(convert_wolfram_number(cmm7_ans) / 24 / 365.25)\n",
    "\n",
    "        mttf_opt_four_node.append(convert_wolfram_number(cmm4opt_ans) / 24 / 365.25)\n",
    "        mttf_opt_five_node.append(convert_wolfram_number(cmm5opt_ans) / 24 / 365.25)\n",
    "        mttf_opt_six_node.append(convert_wolfram_number(cmm6opt_ans) / 24 / 365.25)\n",
    "        mttf_opt_seven_node.append(convert_wolfram_number(cmm7opt_ans) / 24 / 365.25)\n",
    "        mttf_three_one_backup.append(convert_wolfram_number(cmm3_1b_ans) / 24 / 365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72170e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis_value_names = [\n",
    "    (mttf_three_node, \"mttf_three_node\"),\n",
    "    (mttf_four_node, \"mttf_four_node\"),\n",
    "    (mttf_five_node, \"mttf_five_node\"),\n",
    "    (mttf_six_node, \"mttf_six_node\"),\n",
    "    (mttf_seven_node, \"mttf_seven_node\"),\n",
    "    (mttf_opt_three_node, \"mttf_opt_three_node\"),\n",
    "    (mttf_opt_four_node, \"mttf_opt_four_node\"),\n",
    "    (mttf_opt_five_node, \"mttf_opt_five_node\"),\n",
    "    (mttf_opt_six_node, \"mttf_opt_six_node\"),\n",
    "    (mttf_opt_seven_node, \"mttf_opt_seven_node\"),\n",
    "    (mttf_opt_1b_three_node, \"mttf_opt_1b_three_node\"),\n",
    "    (mttf_three_one_backup, \"mttf_three_one_backup\"),\n",
    "    (mttf_three_two_backup, \"mttf_three_two_backup\"),\n",
    "    (mttf_three_three_backup, \"mttf_three_three_backup\"),\n",
    "    (mttf_four_one_backup, \"mttf_four_one_backup\"),\n",
    "    (mttf_four_two_backup, \"mttf_four_two_backup\"),\n",
    "    (mttf_four_three_backup, \"mttf_four_three_backup\"),\n",
    "    (mttf_five_one_backup, \"mttf_five_one_backup\"),\n",
    "    (mttf_five_two_backup, \"mttf_five_two_backup\"),\n",
    "    (mttf_five_three_backup, \"mttf_five_three_backup\"),\n",
    "    (mttf_six_one_backup, \"mttf_six_one_backup\"),\n",
    "    (mttf_six_two_backup, \"mttf_six_two_backup\"),\n",
    "    (mttf_six_three_backup, \"mttf_six_three_backup\"),\n",
    "]\n",
    "\n",
    "mttf_vs_failure_rate = Graph(\n",
    "    title=\"mttf vs failure rate/year\",\n",
    "    x_axis_name=\"failure rate/yr\",\n",
    "    y_axis_name=\"mttf (years)\",\n",
    "    lines=[\n",
    "        Line(x_values=x_axis, y_values=val_name[0], name=val_name[1])\n",
    "        for val_name in y_axis_value_names\n",
    "    ],\n",
    ")\n",
    "\n",
    "make_fig(mttf_vs_failure_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fe787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also try to vary automatic recovery rate + other parameters 5 outputs\n",
    "# Try to get the 5d symbolic mttf\n",
    "# Try to generate graphs automatically +++ Good graph visualization\n",
    "# Try to get parameter sweep sliders for graphs\n",
    "failure_rates = generate_fractions(Fraction(1, 5), Fraction(1, 5 * 24 * 10), 40)\n",
    "x_axis = [float(x) * 24 * 365.25 for x in failure_rates]\n",
    "\n",
    "mttf_three_node = []\n",
    "mttf_four_node = []\n",
    "mttf_five_node = []\n",
    "mttf_six_node = []\n",
    "mttf_seven_node = []\n",
    "\n",
    "mttf_opt_four_node = []\n",
    "mttf_opt_five_node = []\n",
    "mttf_opt_six_node = []\n",
    "mttf_opt_seven_node = []\n",
    "\n",
    "mttf_three_one_backup = []\n",
    "mttf_three_two_backup = []\n",
    "mttf_three_three_backup = []\n",
    "\n",
    "mttf_four_one_backup = []\n",
    "mttf_four_two_backup = []\n",
    "mttf_four_three_backup = []\n",
    "\n",
    "mttf_five_one_backup = []\n",
    "mttf_five_two_backup = []\n",
    "mttf_five_three_backup = []\n",
    "\n",
    "mttf_six_one_backup = []\n",
    "mttf_six_two_backup = []\n",
    "mttf_six_three_backup = []\n",
    "\n",
    "backup_arrs = [\n",
    "    mttf_three_one_backup,\n",
    "    mttf_three_two_backup,\n",
    "    mttf_three_three_backup,\n",
    "    mttf_four_one_backup,\n",
    "    mttf_four_two_backup,\n",
    "    mttf_four_three_backup,\n",
    "    mttf_five_one_backup,\n",
    "    mttf_five_two_backup,\n",
    "    mttf_five_three_backup,\n",
    "    mttf_six_one_backup,\n",
    "    mttf_six_two_backup,\n",
    "    mttf_six_three_backup,\n",
    "]\n",
    "\n",
    "\n",
    "with WolframLanguageSession(my_wolfram_kernel_path) as wolfram_session:\n",
    "    for failure_rps in failure_rates:\n",
    "        params = FailureParameters(\n",
    "            failure_rps=Fraction(1, 50 * 24),\n",
    "            recovery_rps=Fraction(1, 5),\n",
    "            human_recovery_rps=failure_rps,\n",
    "            update_rps=Fraction((60 * 60 * 1000), 10),\n",
    "            outdate_rps=Fraction((60 * 60 * 1000), 10),\n",
    "        )\n",
    "        cmm3 = get_cmm(3, params)\n",
    "        cmm5 = get_cmm(5, params)\n",
    "        cmm4 = get_cmm(4, params)\n",
    "        cmm6 = get_cmm(6, params)\n",
    "        cmm7 = get_cmm(7, params)\n",
    "\n",
    "        cmm4opt = get_dr_cmm(4, params)\n",
    "        cmm5opt = get_dr_cmm(5, params)\n",
    "        cmm6opt = get_dr_cmm(6, params)\n",
    "        cmm7opt = get_dr_cmm(7, params)\n",
    "\n",
    "        cmm3_1b = get_dr_backup_cmm(3, 1, params, params)\n",
    "\n",
    "        cmm3_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm3),\n",
    "                    get_state_to_id_dict(cmm3)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm5_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm5),\n",
    "                    get_state_to_id_dict(cmm5)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm4_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm4),\n",
    "                    get_state_to_id_dict(cmm4)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm6_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm6),\n",
    "                    get_state_to_id_dict(cmm6)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm7_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm7),\n",
    "                    get_state_to_id_dict(cmm7)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        cmm4opt_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm4opt),\n",
    "                    get_state_to_id_dict(cmm4opt)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm5opt_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm5opt),\n",
    "                    get_state_to_id_dict(cmm5opt)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm6opt_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm6opt),\n",
    "                    get_state_to_id_dict(cmm6opt)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        cmm7opt_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm7opt),\n",
    "                    get_state_to_id_dict(cmm7opt)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for num_reps in range(3, 7):\n",
    "            for num_backups in range(1, 4):\n",
    "                cmm = get_dr_backup_cmm(num_reps, num_backups, params, params)\n",
    "                cmm_ans = wolfram_session.evaluate(\n",
    "                    wl.Mean(\n",
    "                        wl.FirstPassageTimeDistribution(\n",
    "                            get_wolfram_markov_model(cmm),\n",
    "                            get_state_to_id_dict(cmm)[\"Failed\"] + 1,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                backup_arrs[(num_reps - 3) * 3 + num_backups - 1].append(\n",
    "                    convert_wolfram_number(cmm_ans) / 24 / 365.25\n",
    "                )\n",
    "\n",
    "        cmm3_1b_ans = wolfram_session.evaluate(\n",
    "            wl.Mean(\n",
    "                wl.FirstPassageTimeDistribution(\n",
    "                    get_wolfram_markov_model(cmm3_1b),\n",
    "                    get_state_to_id_dict(cmm3_1b)[\"Failed\"] + 1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        mttf_three_node.append(convert_wolfram_number(cmm3_ans) / 24 / 365.25)\n",
    "        mttf_five_node.append(convert_wolfram_number(cmm5_ans) / 24 / 365.25)\n",
    "        mttf_four_node.append(convert_wolfram_number(cmm4_ans) / 24 / 365.25)\n",
    "        mttf_six_node.append(convert_wolfram_number(cmm6_ans) / 24 / 365.25)\n",
    "        mttf_seven_node.append(convert_wolfram_number(cmm7_ans) / 24 / 365.25)\n",
    "\n",
    "        mttf_opt_four_node.append(convert_wolfram_number(cmm4opt_ans) / 24 / 365.25)\n",
    "        mttf_opt_five_node.append(convert_wolfram_number(cmm5opt_ans) / 24 / 365.25)\n",
    "        mttf_opt_six_node.append(convert_wolfram_number(cmm6opt_ans) / 24 / 365.25)\n",
    "        mttf_opt_seven_node.append(convert_wolfram_number(cmm7opt_ans) / 24 / 365.25)\n",
    "        mttf_three_one_backup.append(convert_wolfram_number(cmm3_1b_ans) / 24 / 365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis_value_names = [\n",
    "    (mttf_three_node, \"mttf_three_node\"),\n",
    "    (mttf_four_node, \"mttf_four_node\"),\n",
    "    (mttf_five_node, \"mttf_five_node\"),\n",
    "    (mttf_six_node, \"mttf_six_node\"),\n",
    "    (mttf_seven_node, \"mttf_seven_node\"),\n",
    "    (mttf_opt_three_node, \"mttf_opt_three_node\"),\n",
    "    (mttf_opt_four_node, \"mttf_opt_four_node\"),\n",
    "    (mttf_opt_five_node, \"mttf_opt_five_node\"),\n",
    "    (mttf_opt_six_node, \"mttf_opt_six_node\"),\n",
    "    (mttf_opt_seven_node, \"mttf_opt_seven_node\"),\n",
    "    (mttf_opt_1b_three_node, \"mttf_opt_1b_three_node\"),\n",
    "    (mttf_three_one_backup, \"mttf_three_one_backup\"),\n",
    "    (mttf_three_two_backup, \"mttf_three_two_backup\"),\n",
    "    (mttf_three_three_backup, \"mttf_three_three_backup\"),\n",
    "    (mttf_four_one_backup, \"mttf_four_one_backup\"),\n",
    "    (mttf_four_two_backup, \"mttf_four_two_backup\"),\n",
    "    (mttf_four_three_backup, \"mttf_four_three_backup\"),\n",
    "    (mttf_five_one_backup, \"mttf_five_one_backup\"),\n",
    "    (mttf_five_two_backup, \"mttf_five_two_backup\"),\n",
    "    (mttf_five_three_backup, \"mttf_five_three_backup\"),\n",
    "    (mttf_six_one_backup, \"mttf_six_one_backup\"),\n",
    "    (mttf_six_two_backup, \"mttf_six_two_backup\"),\n",
    "    (mttf_six_three_backup, \"mttf_six_three_backup\"),\n",
    "]\n",
    "\n",
    "mttf_vs_failure_rate = Graph(\n",
    "    title=\"mttf vs failure rate/year\",\n",
    "    x_axis_name=\"human recovery rate/yr\",\n",
    "    y_axis_name=\"mttf (years)\",\n",
    "    lines=[\n",
    "        Line(x_values=x_axis, y_values=val_name[0], name=val_name[1])\n",
    "        for val_name in y_axis_value_names\n",
    "    ],\n",
    ")\n",
    "\n",
    "make_fig(mttf_vs_failure_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
