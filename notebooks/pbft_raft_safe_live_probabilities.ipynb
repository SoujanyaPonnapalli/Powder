{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import poisson_binom\n",
    "from scipy.stats import binom\n",
    "from functools import cache\n",
    "from collections.abc import Sequence\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, astuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trad_system = PbftParameters(4,3,4,3,2)\n",
    "wtf = PbftParameters(5,3,3,3,2)\n",
    "new_system = PbftParameters(5,4,4,4,2)\n",
    "big_trad = PbftParameters(7,5,5,5,3)\n",
    "new_big = PbftParameters(8,6,6,6,3)\n",
    "biggest_trad = PbftParameters(10,7,7,7,4)\n",
    "print(pbft_min_unsafe_failures(trad_system), pbft_min_unlive_failures(trad_system))\n",
    "print(pbft_min_unsafe_failures(wtf), pbft_min_unlive_failures(wtf))\n",
    "print(pbft_min_unsafe_failures(new_system), pbft_min_unlive_failures(new_system))\n",
    "print(pbft_min_unsafe_failures(new_system), pbft_min_unlive_failures(big_trad))\n",
    "print(pbft_min_unsafe_failures(new_big), pbft_min_unlive_failures(new_big))\n",
    "print(pbft_min_unsafe_failures(biggest_trad), pbft_min_unlive_failures(biggest_trad))\n",
    "\n",
    "print(p_pbft_safe(new_big, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PbftParameters:\n",
    "    num_nodes: int\n",
    "    prepare_qs: int\n",
    "    commit_qs: int\n",
    "    view_change_qs: int\n",
    "    view_sync_qs: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RaftParameters:\n",
    "    num_nodes: int\n",
    "    commit_qs: int\n",
    "    leader_election_qs: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raft_min_unlive_failures(RaftParameters(6,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.08]*(7-4) + [.01]*4\n",
    "rv = poisson_binom(p)\n",
    "print(rv.cdf(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_val = 1\n",
    "for i in range(0,6):\n",
    "    p = [0.08]*(5-i) + [.01]*i\n",
    "    rv = poisson_binom(p)\n",
    "    cur_val = rv.cdf(2)\n",
    "    print(f'i={i}: {cur_val*100} \\t delta={(1-.9954747392000002)/(1-cur_val)}')\n",
    "    old_val = cur_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0,8):\n",
    "    p = [0.08]*(7-i) + [.01]*i\n",
    "    rv = poisson_binom(p)\n",
    "    cur_val = rv.cdf(3)\n",
    "    print(f'i={i}: {cur_val} \\t delta={(1-.9988237205504003)/(1-cur_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_poisson_raft_safe_and_live(RaftParameters(5,3,3), [0.01]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import comb\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "getcontext().prec = 100  # Set desired precision\n",
    "\n",
    "@cache\n",
    "def decimal_binom_range(num_trials: int, p_success: Decimal, *, min_success=None, max_success=None):\n",
    "    total_probability = Decimal(0.0)\n",
    "\n",
    "    for x in range(min_success, max_success + 1):\n",
    "        # Calculate the probability for exactly x successes\n",
    "        prob_x = comb(num_trials, x) * (p_success ** x) * ((1 - p_success) ** (num_trials - x))\n",
    "        total_probability += prob_x\n",
    "\n",
    "    return total_probability\n",
    "\n",
    "def p_decimal_raft_safe_and_live(raft_parameters: RaftParameters, p_failure: Decimal) -> float:\n",
    "    min_unlive_failures = raft_min_unlive_failures(raft_parameters)\n",
    "    max_unlive_failures = raft_max_unlive_failures(raft_parameters)\n",
    "    min_unsafe_failures = raft_min_unsafe_failures(raft_parameters)\n",
    "    max_unsafe_failures = raft_max_unsafe_failures(raft_parameters)\n",
    "\n",
    "    min_unsafe_or_unlive_failures = min(min_unlive_failures, min_unsafe_failures)\n",
    "    max_unsafe_or_unlive_failures = max(max_unlive_failures, max_unsafe_failures)\n",
    "\n",
    "    return 1 - decimal_binom_range(\n",
    "        num_trials=raft_parameters.num_nodes,\n",
    "        p_success=p_failure,\n",
    "        min_success=min_unsafe_or_unlive_failures,\n",
    "        max_success=max_unsafe_or_unlive_failures,\n",
    "    )\n",
    "\n",
    "p_decimal_raft_safe_and_live(RaftParameters(11,6,6), Decimal(.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def p_binom_range(\n",
    "    num_trials: int, p_success: float, *, min_success=None, max_success=None\n",
    ") -> float:\n",
    "    if min_success is None:\n",
    "        min_success = 0\n",
    "    if max_success is None:\n",
    "        max_success = num_trials\n",
    "    if min_success > max_success:\n",
    "        return 0\n",
    "    return binom.cdf(max_success, num_trials, p_success) - binom.cdf(\n",
    "        min_success - 1, num_trials, p_success\n",
    "    )\n",
    "\n",
    "\n",
    "def p_poisson_binom_range(num_trials: int, p_successes: list[float], * , min_success=None, max_success=None) -> float:\n",
    "    if min_success is None:\n",
    "        min_success = 0\n",
    "    if max_success is None:\n",
    "        max_success = num_trials\n",
    "    if min_success > max_success:\n",
    "        return 0\n",
    "\n",
    "    ub = None\n",
    "    lb = None\n",
    "    if max_success >= num_trials:\n",
    "        ub = 1\n",
    "    else:\n",
    "        ub = poisson_binom.cdf(max_success, num_trials, p_successes)\n",
    "    if min_success <= 0:\n",
    "        lb = 0\n",
    "    else:\n",
    "        lb = poisson_binom.cdf(\n",
    "        min_success - 1, num_trials, p_successes\n",
    "    )\n",
    "    return ub - lb\n",
    "\n",
    "def pbft_min_unsafe_failures(pbft_parameters: PbftParameters) -> int:\n",
    "    \"\"\"\n",
    "    By Inclusion Exclusion: [|quorum1 U quorum2| <= N] === [|quorum1| + |quorum2| - |quorum1 \\\\intersect quorum2| <= N]\n",
    "    The case where [|quorum1| + |quorum2| - Byz <= N] is bad as quorum1, quorum2 could have only byz intersection\n",
    "    Writing it differently: [|quorum1| + |quorum2| - Byz <= N] === [|quorum1| + |quorum2| - N <= Byz]\n",
    "    Therefore if [Byz >= |quorum1| + |quorum2| - N] then quorum1 and quorum2 may only have byz intersection\n",
    "    \"\"\"\n",
    "    # Equivocation requires >= 1 Byz node and prepare quorums to intersect in only byz nodes\n",
    "    min_failures_equivocate_prepare = max(\n",
    "        pbft_parameters.prepare_qs\n",
    "        + pbft_parameters.prepare_qs\n",
    "        - pbft_parameters.num_nodes,\n",
    "        1,\n",
    "    )\n",
    "    # Losing a commit requires commit and view change quorums to not intersect\n",
    "    min_failures_non_persist_commit = (\n",
    "        pbft_parameters.commit_qs\n",
    "        + pbft_parameters.view_change_qs\n",
    "        - pbft_parameters.num_nodes\n",
    "    )\n",
    "\n",
    "    return min(min_failures_equivocate_prepare, min_failures_non_persist_commit)\n",
    "\n",
    "\n",
    "def pbft_max_unsafe_failures(pbft_parameters: PbftParameters) -> int:\n",
    "    # There must be at least one non-byzantine node to create a safety violation\n",
    "    return pbft_parameters.num_nodes\n",
    "\n",
    "\n",
    "def pbft_min_unlive_failures(pbft_parameters: PbftParameters) -> int:\n",
    "    # If [Correct <= biggest_quorum - 1] then we will never complete all quorums needed for consensus\n",
    "    # Rewriting it gives: [N - Byz <= biggest_quorum - 1] === [Byz >= N - biggest_quorum + 1]\n",
    "    biggest_quorum_size = max(\n",
    "        pbft_parameters.prepare_qs,\n",
    "        pbft_parameters.commit_qs,\n",
    "        pbft_parameters.view_change_qs,\n",
    "    )\n",
    "    min_failures_to_not_progress = pbft_parameters.num_nodes - biggest_quorum_size + 1\n",
    "\n",
    "    # PBFT provides that after 1 honest node enters the view, all honest nodes will enter in a bounded time post GST\n",
    "    # PBFT gets this requirement because honest node needs view_change_qs messages, and view_change_qs-Byz will broadcast this\n",
    "    # Then if any honest nodes hear view_sync_qs messages they will broadcast -- therefore we need [view_change_qs - Byz > view_sync_qs - 1]\n",
    "    # If [view_change_qs - Byz <= view_sync_qs - 1] then we won't hit the view-sync_qs threshold\n",
    "    # Equiv [Byz >= view_change_qs - view_sync_qs + 1]\n",
    "    min_failures_to_not_sync_views = (\n",
    "        pbft_parameters.view_change_qs - pbft_parameters.view_sync_qs + 1\n",
    "    )\n",
    "\n",
    "    # if this holds, byz nodes can force constant view changes\n",
    "    min_failures_spam_view_change = min(\n",
    "        pbft_parameters.view_sync_qs, pbft_parameters.view_change_qs\n",
    "    )\n",
    "\n",
    "    return min(\n",
    "        min_failures_to_not_progress,\n",
    "        min_failures_to_not_sync_views,\n",
    "        min_failures_spam_view_change,\n",
    "    )\n",
    "\n",
    "\n",
    "def pbft_max_unlive_failures(pbft_parameters: PbftParameters) -> int:\n",
    "    # Pbft can be unlive no matter how many nodes fail -- i.e. unlive when [min_unlive_failures <= Byz <= __N__]\n",
    "    return pbft_parameters.num_nodes\n",
    "\n",
    "\n",
    "def raft_min_unsafe_failures(raft_parameters: RaftParameters) -> int:\n",
    "    \"\"\"\n",
    "    By Inclusion Exclusion: [|quorum1 U quorum2| <= N] === [|quorum1| + |quorum2| - |quorum1 \\\\intersect quorum2| <= N]\n",
    "    The case where [|quorum1| + |quorum2| - 0 <= N] is bad as quorum1, quorum2 could have no intersection\n",
    "    Raft requires any two leader election quorums to intersect AND the leader election and commit quorums to intersect\n",
    "    Note that this is __not__ dependent on the number of nodes which fail\n",
    "    \"\"\"\n",
    "    do_leader_and_commit_not_intersect = (\n",
    "        raft_parameters.commit_qs + raft_parameters.leader_election_qs\n",
    "        <= raft_parameters.num_nodes\n",
    "    )\n",
    "    do_leader_election_quorums_not_intersect = (\n",
    "        raft_parameters.leader_election_qs + raft_parameters.leader_election_qs\n",
    "        <= raft_parameters.num_nodes\n",
    "    )\n",
    "    # If there are <2 nodes there cannot be a safety violation\n",
    "    is_safety_violation_possible = raft_parameters.num_nodes >= 2\n",
    "\n",
    "    is_raft_unsafe = (\n",
    "        do_leader_and_commit_not_intersect or do_leader_election_quorums_not_intersect\n",
    "    ) and is_safety_violation_possible\n",
    "    if is_raft_unsafe:\n",
    "        # raft is unsafe even if no nodes fail\n",
    "        return 0\n",
    "    # raft is safe even if all nodes fail\n",
    "    return raft_parameters.num_nodes + 1\n",
    "\n",
    "\n",
    "def raft_max_unsafe_failures(raft_parameters: RaftParameters) -> int:\n",
    "    # If there are <2 nodes there cannot be a safety violation\n",
    "    is_violation_possible = raft_parameters.num_nodes >= 2\n",
    "    if is_violation_possible:\n",
    "        return raft_parameters.num_nodes\n",
    "    # raft cannot be unsafe\n",
    "    return -1\n",
    "\n",
    "\n",
    "def raft_min_unlive_failures(raft_parameters: RaftParameters) -> int:\n",
    "    # If [Correct <= biggest_quorum - 1] then we will never complete all quorums needed for consensus\n",
    "    # Rewriting it gives: [N - Crashed <= biggest_quorum - 1] === [Crashed >= N - biggest_quorum + 1]\n",
    "    biggest_quorum_size = max(\n",
    "        raft_parameters.commit_qs, raft_parameters.leader_election_qs\n",
    "    )\n",
    "    min_failures_to_not_progress = raft_parameters.num_nodes - biggest_quorum_size + 1\n",
    "\n",
    "    return min_failures_to_not_progress\n",
    "\n",
    "\n",
    "def raft_max_unlive_failures(raft_parameters: RaftParameters) -> int:\n",
    "    # raft can be unlive no matter how many nodes fail\n",
    "    return raft_parameters.num_nodes\n",
    "\n",
    "\n",
    "def p_pbft_safe(pbft_parameters: PbftParameters, p_failure: float) -> float:\n",
    "    min_unsafe_failures = pbft_min_unsafe_failures(pbft_parameters)\n",
    "    max_unsafe_failures = pbft_max_unsafe_failures(pbft_parameters)\n",
    "\n",
    "    return 1 - p_binom_range(\n",
    "        num_trials=pbft_parameters.num_nodes,\n",
    "        p_success=p_failure,\n",
    "        min_success=min_unsafe_failures,\n",
    "        max_success=max_unsafe_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_pbft_live(pbft_parameters: PbftParameters, p_failure: float) -> float:\n",
    "    min_unlive_failures = pbft_min_unlive_failures(pbft_parameters)\n",
    "    max_unlive_failures = pbft_max_unlive_failures(pbft_parameters)\n",
    "\n",
    "    return 1 - p_binom_range(\n",
    "        num_trials=pbft_parameters.num_nodes,\n",
    "        p_success=p_failure,\n",
    "        min_success=min_unlive_failures,\n",
    "        max_success=max_unlive_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_pbft_safe_and_live(pbft_parameters: PbftParameters, p_failure: float) -> float:\n",
    "    min_unlive_failures = pbft_min_unlive_failures(pbft_parameters)\n",
    "    max_unlive_failures = pbft_max_unlive_failures(pbft_parameters)\n",
    "    min_unsafe_failures = pbft_min_unsafe_failures(pbft_parameters)\n",
    "    max_unsafe_failures = pbft_max_unsafe_failures(pbft_parameters)\n",
    "\n",
    "    min_unsafe_or_unlive_failures = min(min_unlive_failures, min_unsafe_failures)\n",
    "    max_unsafe_or_unlive_failures = max(max_unlive_failures, max_unsafe_failures)\n",
    "\n",
    "    return 1 - p_binom_range(\n",
    "        num_trials=pbft_parameters.num_nodes,\n",
    "        p_success=p_failure,\n",
    "        min_success=min_unsafe_or_unlive_failures,\n",
    "        max_success=max_unsafe_or_unlive_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_raft_safe(raft_parameters: RaftParameters, p_failure: float) -> float:\n",
    "    min_unsafe_failures = raft_min_unsafe_failures(raft_parameters)\n",
    "    max_unsafe_failures = raft_max_unsafe_failures(raft_parameters)\n",
    "\n",
    "    return 1 - p_binom_range(\n",
    "        num_trials=raft_parameters.num_nodes,\n",
    "        p_success=p_failure,\n",
    "        min_success=min_unsafe_failures,\n",
    "        max_success=max_unsafe_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_raft_live(raft_parameters: RaftParameters, p_failure: float) -> float:\n",
    "    min_unlive_failures = raft_min_unlive_failures(raft_parameters)\n",
    "    max_unlive_failures = raft_max_unlive_failures(raft_parameters)\n",
    "\n",
    "    return 1 - p_binom_range(\n",
    "        num_trials=raft_parameters.num_nodes,\n",
    "        p_success=p_failure,\n",
    "        min_success=min_unlive_failures,\n",
    "        max_success=max_unlive_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_raft_safe_and_live(raft_parameters: RaftParameters, p_failure: float) -> float:\n",
    "    min_unlive_failures = raft_min_unlive_failures(raft_parameters)\n",
    "    max_unlive_failures = raft_max_unlive_failures(raft_parameters)\n",
    "    min_unsafe_failures = raft_min_unsafe_failures(raft_parameters)\n",
    "    max_unsafe_failures = raft_max_unsafe_failures(raft_parameters)\n",
    "\n",
    "    min_unsafe_or_unlive_failures = min(min_unlive_failures, min_unsafe_failures)\n",
    "    max_unsafe_or_unlive_failures = max(max_unlive_failures, max_unsafe_failures)\n",
    "\n",
    "    return 1 - p_binom_range(\n",
    "        num_trials=raft_parameters.num_nodes,\n",
    "        p_success=p_failure,\n",
    "        min_success=min_unsafe_or_unlive_failures,\n",
    "        max_success=max_unsafe_or_unlive_failures,\n",
    "    )\n",
    "\n",
    "############\n",
    "\n",
    "def p_poisson_pbft_safe(pbft_parameters: PbftParameters, p_failures: list[float]) -> float:\n",
    "    min_unsafe_failures = pbft_min_unsafe_failures(pbft_parameters)\n",
    "    max_unsafe_failures = pbft_max_unsafe_failures(pbft_parameters)\n",
    "\n",
    "    return 1 - p_poisson_binom_range(\n",
    "        num_trials=pbft_parameters.num_nodes,\n",
    "        p_successes=p_failure,\n",
    "        min_success=min_unsafe_failures,\n",
    "        max_success=max_unsafe_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_poisson_pbft_live(pbft_parameters: PbftParameters, p_failure: list[float]) -> float:\n",
    "    min_unlive_failures = pbft_min_unlive_failures(pbft_parameters)\n",
    "    max_unlive_failures = pbft_max_unlive_failures(pbft_parameters)\n",
    "\n",
    "    return 1 - p_poisson_binom_range(\n",
    "        num_trials=pbft_parameters.num_nodes,\n",
    "        p_successes=p_failure,\n",
    "        min_success=min_unlive_failures,\n",
    "        max_success=max_unlive_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_poisson_pbft_safe_and_live(pbft_parameters: PbftParameters, p_failure: list[float]) -> float:\n",
    "    min_unlive_failures = pbft_min_unlive_failures(pbft_parameters)\n",
    "    max_unlive_failures = pbft_max_unlive_failures(pbft_parameters)\n",
    "    min_unsafe_failures = pbft_min_unsafe_failures(pbft_parameters)\n",
    "    max_unsafe_failures = pbft_max_unsafe_failures(pbft_parameters)\n",
    "\n",
    "    min_unsafe_or_unlive_failures = min(min_unlive_failures, min_unsafe_failures)\n",
    "    max_unsafe_or_unlive_failures = max(max_unlive_failures, max_unsafe_failures)\n",
    "\n",
    "    return 1 - p_poisson_binom_range(\n",
    "        num_trials=pbft_parameters.num_nodes,\n",
    "        p_successes=p_failure,\n",
    "        min_success=min_unsafe_or_unlive_failures,\n",
    "        max_success=max_unsafe_or_unlive_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_poisson_raft_safe(raft_parameters: RaftParameters, p_failure: list[float]) -> float:\n",
    "    min_unsafe_failures = raft_min_unsafe_failures(raft_parameters)\n",
    "    max_unsafe_failures = raft_max_unsafe_failures(raft_parameters)\n",
    "\n",
    "    return 1 - p_poisson_binom_range(\n",
    "        num_trials=raft_parameters.num_nodes,\n",
    "        p_successes=p_failure,\n",
    "        min_success=min_unsafe_failures,\n",
    "        max_success=max_unsafe_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_poisson_raft_live(raft_parameters: RaftParameters, p_failure: list[float]) -> float:\n",
    "    min_unlive_failures = raft_min_unlive_failures(raft_parameters)\n",
    "    max_unlive_failures = raft_max_unlive_failures(raft_parameters)\n",
    "\n",
    "    return 1 - p_poisson_binom_range(\n",
    "        num_trials=raft_parameters.num_nodes,\n",
    "        p_successes=p_failure,\n",
    "        min_success=min_unlive_failures,\n",
    "        max_success=max_unlive_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def p_poisson_raft_safe_and_live(raft_parameters: RaftParameters, p_failure: list[float]) -> float:\n",
    "    min_unlive_failures = raft_min_unlive_failures(raft_parameters)\n",
    "    max_unlive_failures = raft_max_unlive_failures(raft_parameters)\n",
    "    min_unsafe_failures = raft_min_unsafe_failures(raft_parameters)\n",
    "    max_unsafe_failures = raft_max_unsafe_failures(raft_parameters)\n",
    "\n",
    "    min_unsafe_or_unlive_failures = min(min_unlive_failures, min_unsafe_failures)\n",
    "    max_unsafe_or_unlive_failures = max(max_unlive_failures, max_unsafe_failures)\n",
    "\n",
    "    return 1 - p_poisson_binom_range(\n",
    "        num_trials=raft_parameters.num_nodes,\n",
    "        p_successes=p_failure,\n",
    "        min_success=min_unsafe_or_unlive_failures,\n",
    "        max_success=max_unsafe_or_unlive_failures,\n",
    "    )\n",
    "\n",
    "\n",
    "def is_strict_le(t1: Sequence[...], t2: Sequence[...]):\n",
    "    \"\"\"\n",
    "    returns true iff t1 <= t2 for all elements\n",
    "    \"\"\"\n",
    "    for i in range(len(t1)):\n",
    "        if t1[i] > t2[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_array(arr: list[Sequence[...]]):\n",
    "    \"\"\"\n",
    "    removes any elements from arr which are strictly greater than or equal to another element in all components\n",
    "    used to remove parameters which have bigger (worse) quorum sizes __unless__ they have smaller chance to fail\n",
    "\n",
    "    current alg -- just d*n^2 checks\n",
    "    better alg O(d*n*logn) -- make d many max heaps, initilize with one element.\n",
    "    For every element, if it would be added to the top of all heaps, discard it. otherwise add it\n",
    "    \"\"\"\n",
    "    cleaned_arr = []\n",
    "    unique_arr = list(set(arr))\n",
    "    for elem in unique_arr:\n",
    "        is_elem_useful = True\n",
    "        for other_elem in cleaned_arr:\n",
    "            if elem != other_elem and is_strict_le(other_elem, elem):\n",
    "                is_elem_useful = False\n",
    "                break\n",
    "        if is_elem_useful:\n",
    "            cleaned_arr.append(elem)\n",
    "    final_arr = []\n",
    "    for elem in cleaned_arr:\n",
    "        is_elem_useful = True\n",
    "        for other_elem in cleaned_arr:\n",
    "            if elem != other_elem and is_strict_le(other_elem, elem):\n",
    "                is_elem_useful = False\n",
    "                break\n",
    "        if is_elem_useful:\n",
    "            final_arr.append(elem)\n",
    "    return final_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZr2lqTpyQgF"
   },
   "outputs": [],
   "source": [
    "# Calculate All quorum size selections for PBFT\n",
    "prob_failure = 0.01\n",
    "min_num_nodes = 7\n",
    "max_num_nodes = 8\n",
    "pbft_aggeragate_results = []\n",
    "\n",
    "for num_nodes in range(min_num_nodes, max_num_nodes + 1):\n",
    "    for prepare_qs, commit_qs, view_change_qs, view_sync_qs in product(\n",
    "        range(0, num_nodes), repeat=4\n",
    "    ):\n",
    "        pbft_parameters = PbftParameters(\n",
    "            num_nodes=num_nodes,\n",
    "            prepare_qs=prepare_qs,\n",
    "            commit_qs=commit_qs,\n",
    "            view_change_qs=view_change_qs,\n",
    "            view_sync_qs=view_sync_qs,\n",
    "        )\n",
    "\n",
    "        safe_and_live_prob = p_pbft_safe_and_live(pbft_parameters, prob_failure)\n",
    "        safety_prob = p_pbft_safe(pbft_parameters, prob_failure)\n",
    "        live_prob = p_pbft_live(pbft_parameters, prob_failure)\n",
    "\n",
    "        pbft_aggeragate_results.append(\n",
    "            (\n",
    "                num_nodes,\n",
    "                safety_prob,\n",
    "                live_prob,\n",
    "                safe_and_live_prob,\n",
    "                prepare_qs,\n",
    "                commit_qs,\n",
    "                view_change_qs,\n",
    "                view_sync_qs,\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\n",
    "    f\"Aggregrated {len(pbft_aggeragate_results)} many results for all RSMs sizes {min_num_nodes}-{max_num_nodes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap safe/live prob with unsafe/unlive prob so clean_array gets rid of more results which are more unsafe/unlive\n",
    "pbft_altered_aggeregate_results = [\n",
    "    (x[0], 1 - x[1], 1 - x[2], 1 - x[3], x[4], x[5], x[6], x[7])\n",
    "    for x in pbft_aggeragate_results\n",
    "]\n",
    "pbft_cleaned_results = clean_array(pbft_altered_aggeregate_results)\n",
    "pbft_cleaned_results = [\n",
    "    (x[0], 1 - x[1], 1 - x[2], 1 - x[3], x[4], x[5], x[6], x[7])\n",
    "    for x in pbft_cleaned_results\n",
    "]\n",
    "pbft_cleaned_results.sort()\n",
    "\n",
    "print(\n",
    "    f\"After cleaning results there are {len(pbft_cleaned_results)} many unique results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAw-X29czPbW",
    "outputId": "b67b3238-3d91-47ee-b354-aad138119f28"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    pbft_cleaned_results,\n",
    "    columns=[\n",
    "        \"network_size\",\n",
    "        \"safe_prob\",\n",
    "        \"live_prob\",\n",
    "        \"safe_and_live_prob\",\n",
    "        \"x1\",\n",
    "        \"x2\",\n",
    "        \"x3\",\n",
    "        \"x4\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(df.to_string(float_format='%.13f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycQ1BEy0mwD9"
   },
   "outputs": [],
   "source": [
    "# Calculate All quorum size selections for RAFT\n",
    "prob_failure = 0.1\n",
    "min_num_nodes = 20\n",
    "max_num_nodes = 20\n",
    "raft_aggeragate_results = []\n",
    "\n",
    "for num_nodes in range(min_num_nodes, max_num_nodes + 1):\n",
    "    for commit_qs, leader_election_qs in product(range(0, num_nodes), repeat=2):\n",
    "        raft_parameters = RaftParameters(\n",
    "            num_nodes=num_nodes,\n",
    "            commit_qs=commit_qs,\n",
    "            leader_election_qs=leader_election_qs,\n",
    "        )\n",
    "\n",
    "        safe_and_live_prob = p_raft_safe_and_live(raft_parameters, prob_failure)\n",
    "        safety_prob = p_raft_safe(raft_parameters, prob_failure)\n",
    "        live_prob = p_raft_live(raft_parameters, prob_failure)\n",
    "        # durable_prob = 1 - p_binom_range(num_trials=num_nodes, p_success=prob_failure, min_success=raft_parameters.commit_qs)\n",
    "\n",
    "        if safety_prob != 0:\n",
    "            raft_aggeragate_results.append(\n",
    "                (\n",
    "                    num_nodes,\n",
    "                    safety_prob,\n",
    "                    live_prob,\n",
    "                    safe_and_live_prob,\n",
    "                    0,#durable_prob,\n",
    "                    commit_qs,\n",
    "                    leader_election_qs,\n",
    "                )\n",
    "            )\n",
    "\n",
    "print(\n",
    "    f\"Aggregrated {len(raft_aggeragate_results)} many results for all RSMs sizes {min_num_nodes}-{max_num_nodes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap safe/live prob with unsafe/unlive prob so clean_array gets rid of more results which are more unsafe/unlive unless they have smaller quorums\n",
    "raft_altered_aggeregate_results = [\n",
    "    (x[0], 1 - x[1], 1 - x[2], 1 - x[3], 1 - x[4], x[5], x[6]) for x in raft_aggeragate_results\n",
    "]\n",
    "raft_cleaned_results = clean_array(raft_altered_aggeregate_results)\n",
    "raft_cleaned_results = [\n",
    "    (x[0], 1 - x[1], 1 - x[2], (1 - x[3]), 1 - x[4], x[5], x[6]) for x in raft_cleaned_results\n",
    "]\n",
    "raft_cleaned_results.sort()\n",
    "\n",
    "print(\n",
    "    f\"After cleaning results there are {len(raft_cleaned_results)} many unique results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    raft_cleaned_results,\n",
    "    columns=[\n",
    "        \"network_size\",\n",
    "        \"safe_prob\",\n",
    "        \"live_prob\",\n",
    "        \"safe_and_live_prob\",\n",
    "        \"durable_prob\",\n",
    "        \"x1\",\n",
    "        \"x2\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(df.to_string(float_format='%.15f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_bad = Decimal('1E-10')\n",
    "p_lame = (1-Decimal('.9')**10)\n",
    "num_trials = Decimal('20')\n",
    "\n",
    "p_good = (1-p_bad)**num_trials\n",
    "p_not_all_lame = 1 - (1-p_lame)**num_trials\n",
    "print(p_good)\n",
    "print(p_not_all_lame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
